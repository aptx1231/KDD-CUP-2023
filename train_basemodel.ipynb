{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cab\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "import json \n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import sentence_transformers \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B09W9FND7K' 'B09JSPLN1M']</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606244</th>\n",
       "      <td>['B086CYFSKW' 'B0874F9859' 'B086CYFSKW']</td>\n",
       "      <td>B07B5TYD76</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606245</th>\n",
       "      <td>['B09NRZKZ7V' 'B08WJTPV93']</td>\n",
       "      <td>B08L1P4C3D</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606246</th>\n",
       "      <td>['B085JFX7MP' 'B085JGHW8R']</td>\n",
       "      <td>B01MPWVD44</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606247</th>\n",
       "      <td>['B00B0UING2' 'B00B0UING2']</td>\n",
       "      <td>B00D3HYEZ4</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606248</th>\n",
       "      <td>['B092S9D1SD' 'B09XQQ1S72' 'B0852MS7QC' 'B0B1V...</td>\n",
       "      <td>B0B7RX65YP</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3606249 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prev_items   next_item locale\n",
       "0                              ['B09W9FND7K' 'B09JSPLN1M']  B09M7GY217     DE\n",
       "1        ['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...  B001B4THSA     DE\n",
       "2        ['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...  B0767DTG2Q     DE\n",
       "3        ['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...  B0B4R9NN4B     DE\n",
       "4                 ['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']  B0BGVBKWGZ     DE\n",
       "...                                                    ...         ...    ...\n",
       "3606244           ['B086CYFSKW' 'B0874F9859' 'B086CYFSKW']  B07B5TYD76     IT\n",
       "3606245                        ['B09NRZKZ7V' 'B08WJTPV93']  B08L1P4C3D     IT\n",
       "3606246                        ['B085JFX7MP' 'B085JGHW8R']  B01MPWVD44     IT\n",
       "3606247                        ['B00B0UING2' 'B00B0UING2']  B00D3HYEZ4     IT\n",
       "3606248  ['B092S9D1SD' 'B09XQQ1S72' 'B0852MS7QC' 'B0B1V...  B0B7RX65YP     IT\n",
       "\n",
       "[3606249 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3606249, 3)\n",
    "df_train = pd.read_csv('data/sessions_train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B08KQBYV43' '3955350843' '3955350843' '39553...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316966</th>\n",
       "      <td>['B077SZ2C3Y' 'B0B14M3VZX']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316967</th>\n",
       "      <td>['B08KFHDPY9' 'B0851KTSRZ' 'B08KFHDPY9' 'B0851...</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316968</th>\n",
       "      <td>['B07PY1N81F' 'B07Q1Z8SQN' 'B07PY1N81F' 'B07Q1...</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316969</th>\n",
       "      <td>['B01MCQMORK' 'B09JYZ325W']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316970</th>\n",
       "      <td>['B0B8JX92YJ' 'B09TN4MP6V' 'B0BG2LZQSL']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316971 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prev_items locale\n",
       "0       ['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...     DE\n",
       "1                ['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']     DE\n",
       "2       ['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...     DE\n",
       "3       ['B08KQBYV43' '3955350843' '3955350843' '39553...     DE\n",
       "4       ['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...     DE\n",
       "...                                                   ...    ...\n",
       "316966                        ['B077SZ2C3Y' 'B0B14M3VZX']     UK\n",
       "316967  ['B08KFHDPY9' 'B0851KTSRZ' 'B08KFHDPY9' 'B0851...     UK\n",
       "316968  ['B07PY1N81F' 'B07Q1Z8SQN' 'B07PY1N81F' 'B07Q1...     UK\n",
       "316969                        ['B01MCQMORK' 'B09JYZ325W']     UK\n",
       "316970           ['B0B8JX92YJ' 'B09TN4MP6V' 'B0BG2LZQSL']     UK\n",
       "\n",
       "[316971 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (316971, 2)\n",
    "df_test = pd.read_csv('data/sessions_test_task1.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(x):\n",
    "    x = x.replace('[', '').replace(']', '').replace(\"'\", '').replace('\\n', ' ').replace('\\r', ' ')\n",
    "    l = [i for i in x.split() if i]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1min多一些\n",
    "df_train['prev_items'] = df_train['prev_items'].apply(lambda x: str2list(x))\n",
    "df_test['prev_items'] = df_test['prev_items'].apply(lambda x: str2list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B09W9FND7K, B09JSPLN1M]</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606244</th>\n",
       "      <td>[B086CYFSKW, B0874F9859, B086CYFSKW]</td>\n",
       "      <td>B07B5TYD76</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606245</th>\n",
       "      <td>[B09NRZKZ7V, B08WJTPV93]</td>\n",
       "      <td>B08L1P4C3D</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606246</th>\n",
       "      <td>[B085JFX7MP, B085JGHW8R]</td>\n",
       "      <td>B01MPWVD44</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606247</th>\n",
       "      <td>[B00B0UING2, B00B0UING2]</td>\n",
       "      <td>B00D3HYEZ4</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606248</th>\n",
       "      <td>[B092S9D1SD, B09XQQ1S72, B0852MS7QC, B0B1V43MN1]</td>\n",
       "      <td>B0B7RX65YP</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3606249 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prev_items   next_item locale\n",
       "0                                 [B09W9FND7K, B09JSPLN1M]  B09M7GY217     DE\n",
       "1         [B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]  B001B4THSA     DE\n",
       "2        [B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...  B0767DTG2Q     DE\n",
       "3        [B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...  B0B4R9NN4B     DE\n",
       "4                     [B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]  B0BGVBKWGZ     DE\n",
       "...                                                    ...         ...    ...\n",
       "3606244               [B086CYFSKW, B0874F9859, B086CYFSKW]  B07B5TYD76     IT\n",
       "3606245                           [B09NRZKZ7V, B08WJTPV93]  B08L1P4C3D     IT\n",
       "3606246                           [B085JFX7MP, B085JGHW8R]  B01MPWVD44     IT\n",
       "3606247                           [B00B0UING2, B00B0UING2]  B00D3HYEZ4     IT\n",
       "3606248   [B092S9D1SD, B09XQQ1S72, B0852MS7QC, B0B1V43MN1]  B0B7RX65YP     IT\n",
       "\n",
       "[3606249 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['last_item'] = df_train['prev_items'].apply(lambda x: x[-1])\n",
    "df_test['last_item'] = df_test['prev_items'].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3606249, 4), (316971, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc2id = {\n",
    "    'DE': 0,\n",
    "    'JP': 1,\n",
    "    'UK': 2,\n",
    "    'ES': 3,\n",
    "    'FR': 4,\n",
    "    'IT': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.load('data/train_ids.npy')\n",
    "test_ids = np.load('data/test_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338847"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ids = set(train_ids) | set(test_ids)\n",
    "len(total_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "产品特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verfügbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Geräte mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【Auto aufziehbar】: Drücken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 Stück</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551052</th>\n",
       "      <td>B09BW5CDRR</td>\n",
       "      <td>IT</td>\n",
       "      <td>Barbie - Playset Gelateria con Bambola con Mac...</td>\n",
       "      <td>20.48</td>\n",
       "      <td>Barbie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DETTAGLI REALISTICI. Basta inserire la pasta m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551053</th>\n",
       "      <td>B0050IILBM</td>\n",
       "      <td>IT</td>\n",
       "      <td>Braun Silk-épil 1 Depilatore Donna, Epilatore ...</td>\n",
       "      <td>22.61</td>\n",
       "      <td>Braun</td>\n",
       "      <td>Pink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4210201656067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alimentato a corrente per un comodo utilizzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551054</th>\n",
       "      <td>B07W4C5W9D</td>\n",
       "      <td>IT</td>\n",
       "      <td>BoxLegend Sacchetti Sottovuoto Vestiti 6 Pezzi...</td>\n",
       "      <td>14.99</td>\n",
       "      <td>BoxLegend</td>\n",
       "      <td>6 Pezzi.</td>\n",
       "      <td>6 Pezzi (2L + 2M + 2S)</td>\n",
       "      <td>6186666487608_SML</td>\n",
       "      <td>Polietilene Ppa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 Sacchetti in 3 Diverse Misure- Questo set di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551055</th>\n",
       "      <td>B012D0HJXA</td>\n",
       "      <td>IT</td>\n",
       "      <td>Trasportino Pratiko Metal - Accessorio da viag...</td>\n",
       "      <td>18.35</td>\n",
       "      <td>MPS</td>\n",
       "      <td>verde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metallo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRASPORTINO 48X31.5X33CM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551056</th>\n",
       "      <td>B07P5RLXP3</td>\n",
       "      <td>IT</td>\n",
       "      <td>LiCB - Batterie LR1130, batterie alcaline AG10...</td>\n",
       "      <td>6.99</td>\n",
       "      <td>LiCB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 Stück LR1130</td>\n",
       "      <td>LR1130-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denominazione: 20 pezzi di pile alcaline LR113...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1551057 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id locale                                              title  \\\n",
       "0        B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1        B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2        B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3        B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4        B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "...             ...    ...                                                ...   \n",
       "1551052  B09BW5CDRR     IT  Barbie - Playset Gelateria con Bambola con Mac...   \n",
       "1551053  B0050IILBM     IT  Braun Silk-épil 1 Depilatore Donna, Epilatore ...   \n",
       "1551054  B07W4C5W9D     IT  BoxLegend Sacchetti Sottovuoto Vestiti 6 Pezzi...   \n",
       "1551055  B012D0HJXA     IT  Trasportino Pratiko Metal - Accessorio da viag...   \n",
       "1551056  B07P5RLXP3     IT  LiCB - Batterie LR1130, batterie alcaline AG10...   \n",
       "\n",
       "         price         brand              color                    size  \\\n",
       "0        30.95    RED DRAGON                NaN                     NaN   \n",
       "1        17.90   Simply Keto                NaN        750 g (1er Pack)   \n",
       "2        68.89    Sennheiser       Multi-Colour                One size   \n",
       "3        18.99  Amy & Benton         Animal Car                     NaN   \n",
       "4         7.17     PLAYMOBIL  Nicht Zutreffend.                 OneSize   \n",
       "...        ...           ...                ...                     ...   \n",
       "1551052  20.48        Barbie                NaN                     NaN   \n",
       "1551053  22.61         Braun               Pink                     NaN   \n",
       "1551054  14.99     BoxLegend           6 Pezzi.  6 Pezzi (2L + 2M + 2S)   \n",
       "1551055  18.35           MPS              verde                     NaN   \n",
       "1551056   6.99          LiCB                NaN         20 Stück LR1130   \n",
       "\n",
       "                     model            material author  \\\n",
       "0                  RDD0089                 NaN    NaN   \n",
       "1                      NaN                 NaN    NaN   \n",
       "2                   508377          Kunstleder    NaN   \n",
       "3                    2008B  aufziehauto 1 jahr    NaN   \n",
       "4                    70522        Polypropylen    NaN   \n",
       "...                    ...                 ...    ...   \n",
       "1551052              HCN46                 NaN    NaN   \n",
       "1551053      4210201656067                 NaN    NaN   \n",
       "1551054  6186666487608_SML     Polietilene Ppa    NaN   \n",
       "1551055                NaN             Metallo    NaN   \n",
       "1551056          LR1130-20                 NaN    NaN   \n",
       "\n",
       "                                                      desc  \n",
       "0        Amberjacks Steel Dartpfeile sind verfügbar in ...  \n",
       "1        🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2        3.5 MM BUCHSE - Kann problemlos an Geräte mit ...  \n",
       "3        【Auto aufziehbar】: Drücken Sie einfach leicht ...  \n",
       "4                                          Inhalt: 1 Stück  \n",
       "...                                                    ...  \n",
       "1551052  DETTAGLI REALISTICI. Basta inserire la pasta m...  \n",
       "1551053       Alimentato a corrente per un comodo utilizzo  \n",
       "1551054  6 Sacchetti in 3 Diverse Misure- Questo set di...  \n",
       "1551055                           TRASPORTINO 48X31.5X33CM  \n",
       "1551056  Denominazione: 20 pezzi di pile alcaline LR113...  \n",
       "\n",
       "[1551057 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不到1min (1551057, 11)\n",
    "products = pd.read_csv('data/products_train.csv')\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verfügbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Geräte mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【Auto aufziehbar】: Drücken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 Stück</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id locale                                              title  \\\n",
       "0  B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "   price         brand              color              size    model  \\\n",
       "0  30.95    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.90   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.89    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.99  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.17     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  \\\n",
       "0                 NaN    NaN   \n",
       "1                 NaN    NaN   \n",
       "2          Kunstleder    NaN   \n",
       "3  aufziehauto 1 jahr    NaN   \n",
       "4        Polypropylen    NaN   \n",
       "\n",
       "                                                desc  \n",
       "0  Amberjacks Steel Dartpfeile sind verfügbar in ...  \n",
       "1  🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2  3.5 MM BUCHSE - Kann problemlos an Geräte mit ...  \n",
       "3  【Auto aufziehbar】: Drücken Sie einfach leicht ...  \n",
       "4                                    Inhalt: 1 Stück  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_ids = products['id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410675"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ids = len(products_ids)\n",
    "\n",
    "len_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以把训练lgb的那些聚合出来的序列特征，比如平均价格之类的，MLP之后拼接到RNN的输出，一起做预测之类的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = products[products.duplicated(subset=['id'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = duplicated_rows.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows.to_csv('data/duplicated_products.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410675, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.drop_duplicates(subset=['id'], keep='first', inplace=True)\n",
    "products.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verfügbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Geräte mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【Auto aufziehbar】: Drücken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 Stück</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id locale                                              title  \\\n",
       "0  B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "   price         brand              color              size    model  \\\n",
       "0  30.95    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.90   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.89    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.99  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.17     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  \\\n",
       "0                 NaN    NaN   \n",
       "1                 NaN    NaN   \n",
       "2          Kunstleder    NaN   \n",
       "3  aufziehauto 1 jahr    NaN   \n",
       "4        Polypropylen    NaN   \n",
       "\n",
       "                                                desc  \n",
       "0  Amberjacks Steel Dartpfeile sind verfügbar in ...  \n",
       "1  🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2  3.5 MM BUCHSE - Kann problemlos an Geräte mit ...  \n",
       "3  【Auto aufziehbar】: Drücken Sie einfach leicht ...  \n",
       "4                                    Inhalt: 1 Stück  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['len_title'] = products['title'].apply(lambda x : 0 if type(x) == float else len(x))\n",
    "products['len_desc'] = products['desc'].apply(lambda x : 0 if type(x) == float else len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'locale', 'title', 'price', 'brand', 'color', 'size', 'model',\n",
       "       'material', 'author', 'desc', 'len_title', 'len_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['brand', 'color', 'size', 'model', 'material', 'author']\n",
    "num_features = ['price', 'len_title', 'len_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    products['encode_' + f] = le.fit_transform(products[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_bins = 10\n",
    "add_cat_features = []\n",
    "for f in num_features:\n",
    "    discretizer = KBinsDiscretizer(n_bins=dense_bins, encode='ordinal', strategy='kmeans')  # 等频quantile，等宽uniform\n",
    "    products['encode_' + f] = discretizer.fit_transform(np.array(products[f].tolist()).reshape(-1, 1))\n",
    "    add_cat_features.append('encode_' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fe in add_cat_features:\n",
    "    products[fe] = products[fe].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['price', 'len_title', 'len_desc']\n",
    "for fe in num_features:\n",
    "    products[fe] = products[fe].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encode_price', 'encode_len_title', 'encode_len_desc']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_model.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = products['title'].values\n",
    "titles_embedding = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = products['desc'].values\n",
    "descs_embedding = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [2:11:56<00:00, 178.20it/s] \n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(titles, total=len(titles)):\n",
    "    if type(s) == float:\n",
    "        titles_embedding.append(np.zeros(titles_embedding[-1].shape))\n",
    "    else:\n",
    "        titles_embedding.append(sentence_model.encode(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [2:03:08<00:00, 190.93it/s] \n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(descs, total=len(descs)):\n",
    "    if type(s) == float:\n",
    "        descs_embedding.append(np.zeros(descs_embedding[-1].shape))\n",
    "    else:\n",
    "        descs_embedding.append(sentence_model.encode(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/titles_embedding.npy', titles_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/descs_embedding.npy', descs_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1410675, 384), (1410675, 384))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_embedding = np.load('./data/titles_embedding.npy')\n",
    "descs_embedding = np.load('./data/descs_embedding.npy')\n",
    "titles_embedding.shape, descs_embedding.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['locale'] = products['locale'].apply(lambda x: loc2id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>...</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>0</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>0</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>0</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>0</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>0</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  locale                                              title  \\\n",
       "0  B005ZSSN10       0  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD       0  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V       0  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S       0  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D       0      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "       price         brand              color              size    model  \\\n",
       "0  30.950001    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.900000   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.889999    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.990000  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.170000     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  ... len_desc  encode_brand  encode_color  \\\n",
       "0                 NaN    NaN  ...    121.0        112134        203260   \n",
       "1                 NaN    NaN  ...    330.0        124505        203260   \n",
       "2          Kunstleder    NaN  ...     95.0        122979        114264   \n",
       "3  aufziehauto 1 jahr    NaN  ...    191.0          9834         46931   \n",
       "4        Polypropylen    NaN  ...     15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410675, 22)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [f for f in products.columns if f not in ['title', 'desc'] + cat_features]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_csv('./data/products_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551041</th>\n",
       "      <td>B09XN5CXDM</td>\n",
       "      <td>5</td>\n",
       "      <td>578.979980</td>\n",
       "      <td>124.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>116789</td>\n",
       "      <td>55013</td>\n",
       "      <td>109396</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551044</th>\n",
       "      <td>B09S3KGLG6</td>\n",
       "      <td>5</td>\n",
       "      <td>43.490002</td>\n",
       "      <td>195.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>121227</td>\n",
       "      <td>80328</td>\n",
       "      <td>143053</td>\n",
       "      <td>524101</td>\n",
       "      <td>19188</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551046</th>\n",
       "      <td>B00E4L5YPW</td>\n",
       "      <td>5</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52556</td>\n",
       "      <td>39304</td>\n",
       "      <td>6470</td>\n",
       "      <td>257247</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551047</th>\n",
       "      <td>B08B4DFWCR</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>23342</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>57350</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551055</th>\n",
       "      <td>B012D0HJXA</td>\n",
       "      <td>5</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>113.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>89982</td>\n",
       "      <td>170638</td>\n",
       "      <td>218060</td>\n",
       "      <td>524101</td>\n",
       "      <td>18060</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1410675 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  locale       price  len_title  len_desc  encode_brand  \\\n",
       "0        B005ZSSN10       0   30.950001       96.0     121.0        112134   \n",
       "1        B08PRYN6LD       0   17.900000      186.0     330.0        124505   \n",
       "2        B09MBZJ48V       0   68.889999      181.0      95.0        122979   \n",
       "3        B08ZN6F26S       0   18.990000      101.0     191.0          9834   \n",
       "4        B094DGRV7D       0    7.170000       45.0      15.0        105135   \n",
       "...             ...     ...         ...        ...       ...           ...   \n",
       "1551041  B09XN5CXDM       5  578.979980      124.0     250.0        116789   \n",
       "1551044  B09S3KGLG6       5   43.490002      195.0     479.0        121227   \n",
       "1551046  B00E4L5YPW       5    8.410000      144.0      57.0         52556   \n",
       "1551047  B08B4DFWCR       5  100.000000       59.0      85.0         23342   \n",
       "1551055  B012D0HJXA       5   18.350000      113.0      24.0         89982   \n",
       "\n",
       "         encode_color  encode_size  encode_model  encode_material  \\\n",
       "0              203260       218060        426630            45568   \n",
       "1              203260       128007        524101            45568   \n",
       "2              114264       170270        145013            15566   \n",
       "3               46931       218060         67408            29357   \n",
       "4              117844       170305        174527            23064   \n",
       "...               ...          ...           ...              ...   \n",
       "1551041         55013       109396        524101            45568   \n",
       "1551044         80328       143053        524101            19188   \n",
       "1551046         39304         6470        257247            45568   \n",
       "1551047        203260       218060         57350            45568   \n",
       "1551055        170638       218060        524101            18060   \n",
       "\n",
       "         encode_author  encode_price  encode_len_title  encode_len_desc  \n",
       "0                30835             0                 2                2  \n",
       "1                30835             0                 4                5  \n",
       "2                30835             0                 4                1  \n",
       "3                30835             0                 2                3  \n",
       "4                30835             0                 0                0  \n",
       "...                ...           ...               ...              ...  \n",
       "1551041          30835             0                 2                4  \n",
       "1551044          30835             0                 4                7  \n",
       "1551046          30835             0                 3                1  \n",
       "1551047          30835             0                 1                1  \n",
       "1551055          30835             0                 2                0  \n",
       "\n",
       "[1410675 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'locale', 'title', 'price', 'brand', 'color', 'size', 'model',\n",
       "       'material', 'author', 'desc', 'len_title', 'len_desc', 'encode_brand',\n",
       "       'encode_color', 'encode_size', 'encode_model', 'encode_material',\n",
       "       'encode_author', 'encode_price', 'encode_len_title', 'encode_len_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  1410675\n",
       "locale                    6\n",
       "title               1360094\n",
       "price                 37608\n",
       "brand                177189\n",
       "color                203260\n",
       "size                 218060\n",
       "model                524101\n",
       "material              45568\n",
       "author                30835\n",
       "desc                 800044\n",
       "len_title               480\n",
       "len_desc                763\n",
       "encode_brand         177190\n",
       "encode_color         203261\n",
       "encode_size          218061\n",
       "encode_model         524102\n",
       "encode_material       45569\n",
       "encode_author         30836\n",
       "encode_price             10\n",
       "encode_len_title         10\n",
       "encode_len_desc          10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [00:01<00:00, 1173467.39it/s]\n"
     ]
    }
   ],
   "source": [
    "product2id = {}\n",
    "id2product = {}\n",
    "\n",
    "for ind, id_ in enumerate(tqdm(products['id'].values, total=len(products['id']))):\n",
    "    product2id[id_] = ind\n",
    "    id2product[ind] = id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(product2id, open('data/product2id.json', 'w'))\n",
    "json.dump(id2product, open('data/id2product.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2id = json.load(open('data/product2id.json', 'r'))\n",
    "id2product = json.load(open('data/id2product.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2product = {int(k): v for k, v in id2product.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3606249, 4), (316971, 3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B099NQFMG7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B00R9RZ9ZS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B07G7Q5N6G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B08KQBYV43, 3955350843, 3955350843, 395535086...</td>\n",
       "      <td>DE</td>\n",
       "      <td>3955350843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09J945WQR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items locale   last_item\n",
       "0  [B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...     DE  B099NQFMG7\n",
       "1               [B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]     DE  B00R9RZ9ZS\n",
       "2   [B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]     DE  B07G7Q5N6G\n",
       "3  [B08KQBYV43, 3955350843, 3955350843, 395535086...     DE  3955350843\n",
       "4  [B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...     DE  B09J945WQR"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_encoded = df_test.copy()\n",
    "df_test_encoded['locale'] = df_test_encoded['locale'].map(loc2id)\n",
    "df_test_encoded['last_item'] = df_test_encoded['last_item'].map(product2id)\n",
    "df_test_encoded['prev_items'] = df_test_encoded['prev_items'].apply(lambda x: [product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B099NQFMG7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B00R9RZ9ZS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B07G7Q5N6G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B08KQBYV43, 3955350843, 3955350843, 395535086...</td>\n",
       "      <td>DE</td>\n",
       "      <td>3955350843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09J945WQR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items locale   last_item\n",
       "0  [B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...     DE  B099NQFMG7\n",
       "1               [B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]     DE  B00R9RZ9ZS\n",
       "2   [B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]     DE  B07G7Q5N6G\n",
       "3  [B08KQBYV43, 3955350843, 3955350843, 395535086...     DE  3955350843\n",
       "4  [B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...     DE  B09J945WQR"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B09W9FND7K, B09JSPLN1M]</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09JSPLN1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "      <td>B001B4TKA0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "      <td>B00AZYORS2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0B71CHT1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09FKD61R8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items   next_item locale  \\\n",
       "0                           [B09W9FND7K, B09JSPLN1M]  B09M7GY217     DE   \n",
       "1   [B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]  B001B4THSA     DE   \n",
       "2  [B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...  B0767DTG2Q     DE   \n",
       "3  [B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...  B0B4R9NN4B     DE   \n",
       "4               [B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]  B0BGVBKWGZ     DE   \n",
       "\n",
       "    last_item  \n",
       "0  B09JSPLN1M  \n",
       "1  B001B4TKA0  \n",
       "2  B00AZYORS2  \n",
       "3  B0B71CHT1L  \n",
       "4  B09FKD61R8  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = df_train\n",
    "df_train_encoded['locale'] = df_train_encoded['locale'].map(loc2id)\n",
    "df_train_encoded['last_item'] = df_train_encoded['last_item'].map(product2id)\n",
    "df_train_encoded['next_item'] = df_train_encoded['next_item'].map(product2id)\n",
    "df_train_encoded['prev_items'] = df_train_encoded['prev_items'].apply(lambda x: [product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[265193, 83226]</td>\n",
       "      <td>387776</td>\n",
       "      <td>0</td>\n",
       "      <td>83226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[38788, 85634, 4132, 71046]</td>\n",
       "      <td>335301</td>\n",
       "      <td>0</td>\n",
       "      <td>71046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[191882, 516876, 191882, 516876, 191882, 19188...</td>\n",
       "      <td>90141</td>\n",
       "      <td>0</td>\n",
       "      <td>516876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[136959, 261145, 31496, 136959, 261145, 31496,...</td>\n",
       "      <td>214540</td>\n",
       "      <td>0</td>\n",
       "      <td>469511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[291068, 410614, 4219]</td>\n",
       "      <td>338089</td>\n",
       "      <td>0</td>\n",
       "      <td>4219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0                                    [265193, 83226]     387776       0   \n",
       "1                        [38788, 85634, 4132, 71046]     335301       0   \n",
       "2  [191882, 516876, 191882, 516876, 191882, 19188...      90141       0   \n",
       "3  [136959, 261145, 31496, 136959, 261145, 31496,...     214540       0   \n",
       "4                             [291068, 410614, 4219]     338089       0   \n",
       "\n",
       "   last_item  \n",
       "0      83226  \n",
       "1      71046  \n",
       "2     516876  \n",
       "3     469511  \n",
       "4       4219  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410675"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_count = products.shape[0]\n",
    "id_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_encoded = products[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_encoded['id'] = products_encoded['id'].map(product2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  locale      price  len_title  len_desc  encode_brand  encode_color  \\\n",
       "0   0       0  30.950001       96.0     121.0        112134        203260   \n",
       "1   1       0  17.900000      186.0     330.0        124505        203260   \n",
       "2   2       0  68.889999      181.0      95.0        122979        114264   \n",
       "3   3       0  18.990000      101.0     191.0          9834         46931   \n",
       "4   4       0   7.170000       45.0      15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_encoded.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(df_sess_loc, df_test_loc):\n",
    "    res = []\n",
    "    for _, row in tqdm(df_sess_loc.iterrows(), total=len(df_sess_loc)):\n",
    "        prev_items = row['prev_items']\n",
    "        next_item = row['next_item']\n",
    "        prev_items.append(next_item)\n",
    "        res.append(prev_items)\n",
    "    \n",
    "    for _, row in tqdm(df_test_loc.iterrows(), total=len(df_test_loc)):\n",
    "        prev_items = row['prev_items']\n",
    "        res.append(prev_items)\n",
    "    \n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3606249/3606249 [03:39<00:00, 16439.99it/s]\n",
      "100%|██████████| 316971/316971 [00:17<00:00, 17684.62it/s]\n"
     ]
    }
   ],
   "source": [
    "id_seqs = get_seq(df_train_encoded, df_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/id_seqs.npy', id_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_window = 3\n",
    "w2v_min_count = 1\n",
    "w2v_epochs = 500\n",
    "w2v_vector_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec = Word2Vec(sentences=id_seqs, window=w2v_window, min_count=w2v_min_count, workers=40, epochs=w2v_epochs, vector_size=w2v_vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec.wv.save_word2vec_format('./data/word2vec_{}_{}_{}_{}.txt'.format(w2v_vector_size, w2v_epochs, w2v_window, w2v_min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec.save('./data/word2vec_{}_{}_{}_{}.pt'.format(w2v_vector_size, w2v_epochs, w2v_window, w2v_min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec = Word2Vec.load('./data/word2vec_{}_{}_{}_{}.pt'.format(w2v_vector_size, w2v_epochs, w2v_window, w2v_min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [00:03<00:00, 358352.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405867\n",
      "1405878\n",
      "1405945\n",
      "1405974\n",
      "1406057\n",
      "1406093\n",
      "1406100\n",
      "1406105\n",
      "1406131\n",
      "1406163\n",
      "1406216\n",
      "1406225\n",
      "1406264\n",
      "1406326\n",
      "1406338\n",
      "1406353\n",
      "1406367\n",
      "1406398\n",
      "1406417\n",
      "1406418\n",
      "1406442\n",
      "1406462\n",
      "1406477\n",
      "1406498\n",
      "1406522\n",
      "1406527\n",
      "1406545\n",
      "1406571\n",
      "1406617\n",
      "1406634\n",
      "1406650\n",
      "1406666\n",
      "1406667\n",
      "1406688\n",
      "1406713\n",
      "1406729\n",
      "1406735\n",
      "1406736\n",
      "1406780\n",
      "1406834\n",
      "1406882\n",
      "1406925\n",
      "1406931\n",
      "1406932\n",
      "1406939\n",
      "1406941\n",
      "1406979\n",
      "1406989\n",
      "1407032\n",
      "1407058\n",
      "1407099\n",
      "1407108\n",
      "1407130\n",
      "1407131\n",
      "1407141\n",
      "1407143\n",
      "1407168\n",
      "1407179\n",
      "1407220\n",
      "1407225\n",
      "1407230\n",
      "1407237\n",
      "1407246\n",
      "1407261\n",
      "1407267\n",
      "1407280\n",
      "1407312\n",
      "1407322\n",
      "1407337\n",
      "1407353\n",
      "1407438\n",
      "1407463\n",
      "1407472\n",
      "1407479\n",
      "1407491\n",
      "1407502\n",
      "1407557\n",
      "1407582\n",
      "1407606\n",
      "1407630\n",
      "1407642\n",
      "1407674\n",
      "1407713\n",
      "1407740\n",
      "1407757\n",
      "1407855\n",
      "1407864\n",
      "1407881\n",
      "1407885\n",
      "1407887\n",
      "1407907\n",
      "1407918\n",
      "1407929\n",
      "1407970\n",
      "1407972\n",
      "1407980\n",
      "1408010\n",
      "1408020\n",
      "1408050\n",
      "1408051\n",
      "1408065\n",
      "1408090\n",
      "1408125\n",
      "1408130\n",
      "1408132\n",
      "1408149\n",
      "1408184\n",
      "1408198\n",
      "1408199\n",
      "1408206\n",
      "1408236\n",
      "1408259\n",
      "1408289\n",
      "1408404\n",
      "1408434\n",
      "1408443\n",
      "1408496\n",
      "1408529\n",
      "1408538\n",
      "1408550\n",
      "1408641\n",
      "1408643\n",
      "1408699\n",
      "1408729\n",
      "1408747\n",
      "1408754\n",
      "1408757\n",
      "1408770\n",
      "1408790\n",
      "1408812\n",
      "1408819\n",
      "1408841\n",
      "1408851\n",
      "1408882\n",
      "1408892\n",
      "1408909\n",
      "1408956\n",
      "1409000\n",
      "1409008\n",
      "1409145\n",
      "1409151\n",
      "1409228\n",
      "1409251\n",
      "1409254\n",
      "1409286\n",
      "1409345\n",
      "1409368\n",
      "1409424\n",
      "1409445\n",
      "1409471\n",
      "1409585\n",
      "1409587\n",
      "1409603\n",
      "1409632\n",
      "1409640\n",
      "1409682\n",
      "1409716\n",
      "1409732\n",
      "1409738\n",
      "1409775\n",
      "1409808\n",
      "1409837\n",
      "1409841\n",
      "1409877\n",
      "1409901\n",
      "1409906\n",
      "1409914\n",
      "1409929\n",
      "1409930\n",
      "1409964\n",
      "1409966\n",
      "1410007\n",
      "1410018\n",
      "1410023\n",
      "1410025\n",
      "1410090\n",
      "1410096\n",
      "1410115\n",
      "1410126\n",
      "1410132\n",
      "1410217\n",
      "1410334\n",
      "1410399\n",
      "1410407\n",
      "1410410\n",
      "1410448\n",
      "1410471\n",
      "1410533\n",
      "1410600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_embedding = []\n",
    "for word in tqdm(range(id_count)):\n",
    "    try:\n",
    "        word2vec_embedding.append(id_word2vec.wv[word])\n",
    "    except:\n",
    "        # 部分word没有出现在id_seqs里边，就是不存在历史的那些id\n",
    "        print(word)\n",
    "        word2vec_embedding.append(np.zeros(w2v_vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/word2vec_embedding.npy', word2vec_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410675, 128)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_embedding = np.load('./data/word2vec_embedding.npy')\n",
    "word2vec_embedding.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[265193, 83226]</td>\n",
       "      <td>387776</td>\n",
       "      <td>0</td>\n",
       "      <td>83226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[38788, 85634, 4132, 71046]</td>\n",
       "      <td>335301</td>\n",
       "      <td>0</td>\n",
       "      <td>71046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[191882, 516876, 191882, 516876, 191882, 19188...</td>\n",
       "      <td>90141</td>\n",
       "      <td>0</td>\n",
       "      <td>516876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[136959, 261145, 31496, 136959, 261145, 31496,...</td>\n",
       "      <td>214540</td>\n",
       "      <td>0</td>\n",
       "      <td>469511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[291068, 410614, 4219]</td>\n",
       "      <td>338089</td>\n",
       "      <td>0</td>\n",
       "      <td>4219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0                                    [265193, 83226]     387776       0   \n",
       "1                        [38788, 85634, 4132, 71046]     335301       0   \n",
       "2  [191882, 516876, 191882, 516876, 191882, 19188...      90141       0   \n",
       "3  [136959, 261145, 31496, 136959, 261145, 31496,...     214540       0   \n",
       "4                             [291068, 410614, 4219]     338089       0   \n",
       "\n",
       "   last_item  \n",
       "0      83226  \n",
       "1      71046  \n",
       "2     516876  \n",
       "3     469511  \n",
       "4       4219  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[370409, 234018, 236816, 3188, 42450, 20661, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>26063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[136109, 425018, 425018]</td>\n",
       "      <td>0</td>\n",
       "      <td>425018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[36017, 46492, 511894, 46492]</td>\n",
       "      <td>0</td>\n",
       "      <td>46492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52581, 387953, 387953, 507424, 224806, 52581,...</td>\n",
       "      <td>0</td>\n",
       "      <td>387953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[371901, 388062, 401264, 449222, 248094, 43829...</td>\n",
       "      <td>0</td>\n",
       "      <td>96347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  locale  last_item\n",
       "0  [370409, 234018, 236816, 3188, 42450, 20661, 2...       0      26063\n",
       "1                           [136109, 425018, 425018]       0     425018\n",
       "2                      [36017, 46492, 511894, 46492]       0      46492\n",
       "3  [52581, 387953, 387953, 507424, 224806, 52581,...       0     387953\n",
       "4  [371901, 388062, 401264, 449222, 248094, 43829...       0      96347"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  locale      price  len_title  len_desc  encode_brand  encode_color  \\\n",
       "0   0       0  30.950001       96.0     121.0        112134        203260   \n",
       "1   1       0  17.900000      186.0     330.0        124505        203260   \n",
       "2   2       0  68.889999      181.0      95.0        122979        114264   \n",
       "3   3       0  18.990000      101.0     191.0          9834         46931   \n",
       "4   4       0   7.170000       45.0      15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3606249, 5), (316971, 3))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.shape, df_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 训练集的部分样本召回的时候，没有找到真实的label。这些对于训练来说就没有用了！修改一下，看看要不要直接把label加进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 召回的结果\n",
    "train_preds = pickle.load(open('./data/train_preds_all.pkl', 'rb'))\n",
    "test_preds = pickle.load(open('./data/test_preds_all.pkl', 'rb'))\n",
    "len(train_preds), len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_encoded = []\n",
    "for x in train_preds:\n",
    "    train_preds_encoded.append([product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_encoded = []\n",
    "for x in test_preds:\n",
    "    test_preds_encoded.append([product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3606249, 316971)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_preds_encoded), len(test_preds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_preds_encoded, open('./data/train_preds_all_encoded.pkl', 'wb'))\n",
    "pickle.dump(test_preds_encoded, open('./data/test_preds_all_encoded.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_encoded = pickle.load(open('./data/train_preds_all_encoded.pkl', 'rb'))\n",
    "test_preds_encoded = pickle.load(open('./data/test_preds_all_encoded.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded['recall'] = train_preds_encoded\n",
    "df_test_encoded['recall'] = test_preds_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[265193, 83226]</td>\n",
       "      <td>387776</td>\n",
       "      <td>0</td>\n",
       "      <td>83226</td>\n",
       "      <td>[265193, 387776, 174133, 54056, 236419, 374995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[38788, 85634, 4132, 71046]</td>\n",
       "      <td>335301</td>\n",
       "      <td>0</td>\n",
       "      <td>71046</td>\n",
       "      <td>[335301, 484264, 153628, 725260, 654971, 69944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[191882, 516876, 191882, 516876, 191882, 19188...</td>\n",
       "      <td>90141</td>\n",
       "      <td>0</td>\n",
       "      <td>516876</td>\n",
       "      <td>[191882, 90141, 111147, 123364, 405548, 320543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[136959, 261145, 31496, 136959, 261145, 31496,...</td>\n",
       "      <td>214540</td>\n",
       "      <td>0</td>\n",
       "      <td>469511</td>\n",
       "      <td>[375995, 219917, 136959, 285874, 506621, 26114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[291068, 410614, 4219]</td>\n",
       "      <td>338089</td>\n",
       "      <td>0</td>\n",
       "      <td>4219</td>\n",
       "      <td>[338089, 435967, 210849, 221386, 153628, 72526...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0                                    [265193, 83226]     387776       0   \n",
       "1                        [38788, 85634, 4132, 71046]     335301       0   \n",
       "2  [191882, 516876, 191882, 516876, 191882, 19188...      90141       0   \n",
       "3  [136959, 261145, 31496, 136959, 261145, 31496,...     214540       0   \n",
       "4                             [291068, 410614, 4219]     338089       0   \n",
       "\n",
       "   last_item                                             recall  \n",
       "0      83226  [265193, 387776, 174133, 54056, 236419, 374995...  \n",
       "1      71046  [335301, 484264, 153628, 725260, 654971, 69944...  \n",
       "2     516876  [191882, 90141, 111147, 123364, 405548, 320543...  \n",
       "3     469511  [375995, 219917, 136959, 285874, 506621, 26114...  \n",
       "4       4219  [338089, 435967, 210849, 221386, 153628, 72526...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[370409, 234018, 236816, 3188, 42450, 20661, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>26063</td>\n",
       "      <td>[65806, 160459, 236816, 311332, 437685, 329918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[136109, 425018, 425018]</td>\n",
       "      <td>0</td>\n",
       "      <td>425018</td>\n",
       "      <td>[12377, 136109, 510746, 335229, 100932, 357096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[36017, 46492, 511894, 46492]</td>\n",
       "      <td>0</td>\n",
       "      <td>46492</td>\n",
       "      <td>[511894, 46492, 36017, 204024, 199383, 409670,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52581, 387953, 387953, 507424, 224806, 52581,...</td>\n",
       "      <td>0</td>\n",
       "      <td>387953</td>\n",
       "      <td>[507424, 387953, 177699, 316651, 224806, 52581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[371901, 388062, 401264, 449222, 248094, 43829...</td>\n",
       "      <td>0</td>\n",
       "      <td>96347</td>\n",
       "      <td>[43829, 248094, 446203, 158521, 162660, 399730...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  locale  last_item  \\\n",
       "0  [370409, 234018, 236816, 3188, 42450, 20661, 2...       0      26063   \n",
       "1                           [136109, 425018, 425018]       0     425018   \n",
       "2                      [36017, 46492, 511894, 46492]       0      46492   \n",
       "3  [52581, 387953, 387953, 507424, 224806, 52581,...       0     387953   \n",
       "4  [371901, 388062, 401264, 449222, 248094, 43829...       0      96347   \n",
       "\n",
       "                                              recall  \n",
       "0  [65806, 160459, 236816, 311332, 437685, 329918...  \n",
       "1  [12377, 136109, 510746, 335229, 100932, 357096...  \n",
       "2  [511894, 46492, 36017, 204024, 199383, 409670,...  \n",
       "3  [507424, 387953, 177699, 316651, 224806, 52581...  \n",
       "4  [43829, 248094, 446203, 158521, 162660, 399730...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_encoded['next_item'] = [id_count] * len(df_test_encoded)\n",
    "df_test_encoded.insert(1, 'next_item', [id_count] * len(df_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[370409, 234018, 236816, 3188, 42450, 20661, 2...</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>26063</td>\n",
       "      <td>[65806, 160459, 236816, 311332, 437685, 329918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[136109, 425018, 425018]</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>425018</td>\n",
       "      <td>[12377, 136109, 510746, 335229, 100932, 357096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[36017, 46492, 511894, 46492]</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>46492</td>\n",
       "      <td>[511894, 46492, 36017, 204024, 199383, 409670,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52581, 387953, 387953, 507424, 224806, 52581,...</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>387953</td>\n",
       "      <td>[507424, 387953, 177699, 316651, 224806, 52581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[371901, 388062, 401264, 449222, 248094, 43829...</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>96347</td>\n",
       "      <td>[43829, 248094, 446203, 158521, 162660, 399730...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0  [370409, 234018, 236816, 3188, 42450, 20661, 2...    1410675       0   \n",
       "1                           [136109, 425018, 425018]    1410675       0   \n",
       "2                      [36017, 46492, 511894, 46492]    1410675       0   \n",
       "3  [52581, 387953, 387953, 507424, 224806, 52581,...    1410675       0   \n",
       "4  [371901, 388062, 401264, 449222, 248094, 43829...    1410675       0   \n",
       "\n",
       "   last_item                                             recall  \n",
       "0      26063  [65806, 160459, 236816, 311332, 437685, 329918...  \n",
       "1     425018  [12377, 136109, 510746, 335229, 100932, 357096...  \n",
       "2      46492  [511894, 46492, 36017, 204024, 199383, 409670,...  \n",
       "3     387953  [507424, 387953, 177699, 316651, 224806, 52581...  \n",
       "4      96347  [43829, 248094, 446203, 158521, 162660, 399730...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  locale      price  len_title  len_desc  encode_brand  encode_color  \\\n",
       "0   0       0  30.950001       96.0     121.0        112134        203260   \n",
       "1   1       0  17.900000      186.0     330.0        124505        203260   \n",
       "2   2       0  68.889999      181.0      95.0        122979        114264   \n",
       "3   3       0  18.990000      101.0     191.0          9834         46931   \n",
       "4   4       0   7.170000       45.0      15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded[['prev_items', 'next_item', 'locale', 'last_item']].to_csv('data/df_train_encoded.csv', index=False)\n",
    "df_test_encoded[['prev_items', 'next_item', 'locale', 'last_item']].to_csv('data/df_test_encoded.csv', index=False)\n",
    "products_encoded.to_csv('./data/products_encoded.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1410675, 384) (1410675, 384)\n",
      "1410675 1410675\n",
      "(1410675, 128)\n",
      "(3606249, 4) (316971, 4) (1410675, 14)\n",
      "3606249 316971\n"
     ]
    }
   ],
   "source": [
    "loc2id = {\n",
    "    'DE': 0,\n",
    "    'JP': 1,\n",
    "    'UK': 2,\n",
    "    'ES': 3,\n",
    "    'FR': 4,\n",
    "    'IT': 5\n",
    "}\n",
    "\n",
    "titles_embedding = np.load('./data/titles_embedding.npy')\n",
    "descs_embedding = np.load('./data/descs_embedding.npy')\n",
    "print(titles_embedding.shape, descs_embedding.shape)\n",
    "\n",
    "product2id = json.load(open('data/product2id.json', 'r'))\n",
    "id2product = json.load(open('data/id2product.json', 'r'))\n",
    "id2product = {int(k): v for k, v in id2product.items()}\n",
    "print(len(product2id), len(id2product))\n",
    "\n",
    "word2vec_embedding = np.load('./data/word2vec_embedding.npy')\n",
    "print(word2vec_embedding.shape)\n",
    "\n",
    "df_train_encoded = pd.read_csv('data/df_train_encoded.csv')\n",
    "df_test_encoded = pd.read_csv('data/df_test_encoded.csv')\n",
    "products_encoded = pd.read_csv('./data/products_encoded.csv')\n",
    "print(df_train_encoded.shape, df_test_encoded.shape, products_encoded.shape)\n",
    "\n",
    "id_count = products_encoded.shape[0]\n",
    "\n",
    "train_preds_encoded = pickle.load(open('./data/train_preds_all_encoded.pkl', 'rb'))\n",
    "test_preds_encoded = pickle.load(open('./data/test_preds_all_encoded.pkl', 'rb'))\n",
    "print(len(train_preds_encoded), len(test_preds_encoded))\n",
    "\n",
    "df_train_encoded['recall'] = train_preds_encoded\n",
    "df_test_encoded['recall'] = test_preds_encoded\n",
    "\n",
    "df_train_encoded['prev_items'] = df_train_encoded['prev_items'].apply(eval)\n",
    "df_test_encoded['prev_items'] = df_test_encoded['prev_items'].apply(eval)\n",
    "\n",
    "num_features = ['price', 'len_title', 'len_desc']\n",
    "for fe in num_features:\n",
    "    products_encoded[fe] = products_encoded[fe].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNDataset(Dataset):\n",
    "    def __init__(self, df, product2id):\n",
    "        super(NNDataset, self).__init__()\n",
    "        self.df = df.copy()\n",
    "        self.product2id = product2id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ['prev_items', 'next_item', 'locale', 'last_item', 'recall']\n",
    "        sample = self.df.iloc[idx].values\n",
    "        return sample[0], sample[2], sample[4], sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_dim = 16\n",
    "# dense_bins = 10\n",
    "# hid_dim = 256\n",
    "# dropout = 0.5\n",
    "# layers = 4\n",
    "\n",
    "# learning_rate = 0.001\n",
    "# weight_decay = 0.00001\n",
    "# lr_patience = 5\n",
    "# lr_decay_ratio = 0.1\n",
    "# batch_size = 256\n",
    "# epochs = 20\n",
    "# lr = 1e-3\n",
    "# log_every = 100\n",
    "# early_stop = True\n",
    "# patience = 10\n",
    "# kfold = 5\n",
    "# device = torch.device('cuda:1')\n",
    "\n",
    "# w2v_window = 3\n",
    "# w2v_min_count = 1\n",
    "# w2v_epochs = 500\n",
    "# w2v_vector_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = NNDataset(df_train_encoded, product2id)\n",
    "# test_set = NNDataset(df_test_encoded, product2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(indices):\n",
    "    batch_prev_items = []\n",
    "    batch_locale = []\n",
    "    batch_candidate_set = []\n",
    "    batch_len = []\n",
    "    batch_mask = []\n",
    "    batch_label = []\n",
    "    batch_label_index = []  # 交叉熵需要的是label在候选集中的index\n",
    "    for item in indices:\n",
    "        batch_len.append(len(item[0]))  # prev_items\n",
    "    max_len = max(batch_len)\n",
    "    for item in indices:\n",
    "        l = len(item[0])\n",
    "        batch_mask.append([1] * (l) + [0] * (max_len - l))  # 0代表padding的位置，需要mask\n",
    "    for item in indices:\n",
    "        # ['prev_items', 'locale', 'recall', 'next_item']\n",
    "        prev_items = item[0].copy()\n",
    "        while (len(prev_items) < max_len):\n",
    "            prev_items.append(id_count)  # embdding的时候id_count+1，把id_count作为padding了\n",
    "        batch_prev_items.append(prev_items)\n",
    "        batch_locale.append(item[1])\n",
    "        batch_candidate_set.append(item[2].copy())\n",
    "        batch_label.append(item[3])\n",
    "        if item[3] in item[2]:\n",
    "            batch_label_index.append(item[2].index(item[3]))\n",
    "        else:\n",
    "            batch_label_index.append(len(item[2]))\n",
    "    return [torch.LongTensor(batch_prev_items).to(device), torch.LongTensor(batch_locale).to(device), \n",
    "            torch.LongTensor(batch_candidate_set).to(device),\n",
    "            torch.LongTensor(batch_len).to(device), torch.LongTensor(batch_mask).to(device), \n",
    "            torch.LongTensor(batch_label).to(device), torch.LongTensor(batch_label_index).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "# test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for i, (batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "#     # print(batch_prev_items.shape, batch_locale.shape, batch_candidate_set.shape, batch_len.shape, batch_mask.shape, batch_label.shape, batch_label_index.shape)\n",
    "#     cnt += (batch_label_index == 100).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt / len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index) in enumerate(test_loader):\n",
    "#     print(batch_prev_items.shape, batch_locale.shape, batch_candidate_set.shape, batch_len.shape, batch_mask.shape, batch_label.shape, batch_label_index.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader), len(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.locale_emb = nn.Embedding(len(loc2id), self.emb_dim)\n",
    "        \n",
    "        self.price_emb = nn.Linear(1, self.emb_dim)\n",
    "        self.len_title_emb = nn.Linear(1, self.emb_dim)\n",
    "        self.len_desc_emb = nn.Linear(1, self.emb_dim)\n",
    "        \n",
    "        self.encode_brand_emb = nn.Embedding(products_encoded['encode_brand'].nunique(), self.emb_dim)\n",
    "        self.encode_color_emb = nn.Embedding(products_encoded['encode_color'].nunique(), self.emb_dim)\n",
    "        self.encode_size_emb = nn.Embedding(products_encoded['encode_size'].nunique(), self.emb_dim)\n",
    "        self.encode_model_emb = nn.Embedding(products_encoded['encode_model'].nunique(), self.emb_dim)\n",
    "        self.encode_material_emb = nn.Embedding(products_encoded['encode_material'].nunique(), self.emb_dim)\n",
    "        self.encode_author_emb = nn.Embedding(products_encoded['encode_author'].nunique(), self.emb_dim)\n",
    "\n",
    "        self.encode_price_emb = nn.Embedding(dense_bins, self.emb_dim)\n",
    "        self.encode_len_title_emb = nn.Embedding(dense_bins, self.emb_dim)\n",
    "        self.encode_len_desc_emb = nn.Embedding(dense_bins, self.emb_dim)\n",
    "\n",
    "    def load_init():\n",
    "        pass\n",
    "\n",
    "    def forward(self, batch_products):\n",
    "        \"\"\"\n",
    "            batch_products: dict \n",
    "        \"\"\"\n",
    "        locale_emb = self.locale_emb(batch_products['locale'])\n",
    "        \n",
    "        price_emb = self.price_emb(batch_products['price'].unsqueeze(-1))\n",
    "        len_title_emb = self.len_title_emb(batch_products['len_title'].unsqueeze(-1))\n",
    "        len_desc_emb = self.len_desc_emb(batch_products['len_desc'].unsqueeze(-1))\n",
    "        \n",
    "        encode_brand_emb = self.encode_brand_emb(batch_products['encode_brand'])\n",
    "        encode_color_emb = self.encode_color_emb(batch_products['encode_color'])\n",
    "        encode_size_emb = self.encode_size_emb(batch_products['encode_size'])\n",
    "        encode_model_emb = self.encode_model_emb(batch_products['encode_model'])\n",
    "        encode_material_emb = self.encode_material_emb(batch_products['encode_material'])\n",
    "        encode_author_emb = self.encode_author_emb(batch_products['encode_author'])\n",
    "\n",
    "        encode_price_emb = self.encode_price_emb(batch_products['encode_price'])\n",
    "        encode_len_title_emb = self.encode_len_title_emb(batch_products['encode_len_title'])\n",
    "        encode_len_desc_emb = self.encode_len_desc_emb(batch_products['encode_len_desc'])\n",
    "\n",
    "        # 将所有特征的表征按照一定的方式组合起来得到这个产品的向量表示\n",
    "        products_vec = torch.cat([locale_emb, \n",
    "                                  price_emb, len_title_emb, len_desc_emb,\n",
    "                                  encode_brand_emb, encode_color_emb, encode_size_emb, \n",
    "                                  encode_model_emb, encode_material_emb, encode_author_emb, \n",
    "                                  encode_price_emb, encode_len_title_emb, encode_len_desc_emb], dim=1)\n",
    "        return products_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, products_input):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.product_fea = Product().to(device)\n",
    "        product_fea_emb = self.product_fea(products_input)  # (id_count, 208)\n",
    "        self.padding_emb = torch.zeros((1, product_fea_emb.shape[1]), requires_grad=False).to(device)\n",
    "        self.product_fea_emb = torch.cat([product_fea_emb, self.padding_emb], dim=0)  # (id_count + 1, 208)\n",
    "        # self.title_emb = nn.Embedding(id_count + 1, embedding_dim=384, padding_idx=id_count)\n",
    "        # self.title_linear = nn.Linear(384, self.emb_dim * 2)\n",
    "        # self.desc_emb = nn.Embedding(id_count + 1, embedding_dim=384, padding_idx=id_count)\n",
    "        # self.desc_linear = nn.Linear(384, self.emb_dim * 2)\n",
    "        self.w2v_emb = nn.Embedding(id_count + 1, embedding_dim=w2v_vector_size, padding_idx=id_count)\n",
    "        self.w2v_linear = nn.Linear(w2v_vector_size, self.emb_dim * 2)\n",
    "        self.load_pretrain()\n",
    "    \n",
    "    def load_pretrain(self):\n",
    "        # self.title_emb.weight.data[:id_count].copy_(torch.tensor(titles_embedding))\n",
    "        # self.desc_emb.weight.data[:id_count].copy_(torch.tensor(descs_embedding))\n",
    "        self.w2v_emb.weight.data[:id_count].copy_(torch.tensor(word2vec_embedding))\n",
    "\n",
    "    def forward(self, batch_prev_items, batch_candidate_set=None):\n",
    "        \"\"\"\n",
    "            batch_prev_items: (B, len)\n",
    "            batch_candidate_set: (B, 100)\n",
    "        \"\"\"\n",
    "        # print(batch_prev_items.shape, batch_candidate_set.shape, batch_label.shape)\n",
    "        # print(self.product_fea_emb[batch_prev_items].shape)\n",
    "        # 对输入序列中的每个商品，获取它的嵌入表示并拼接\n",
    "        batch_prev_items_emb = torch.cat([\n",
    "            self.product_fea_emb[batch_prev_items],  # 商品特征嵌入\n",
    "            # self.title_linear(self.title_emb(batch_prev_items)), \n",
    "            # self.desc_linear(self.desc_emb(batch_prev_items)), \n",
    "            self.w2v_linear(self.w2v_emb(batch_prev_items))\n",
    "        ], dim=-1)\n",
    "        # 对候选集中的每个商品，获取它的嵌入表示并拼接\n",
    "        if batch_candidate_set is not None:\n",
    "            batch_candidate_set_emb = torch.cat([\n",
    "                self.product_fea_emb[batch_candidate_set],  # 商品特征嵌入\n",
    "                # self.title_linear(self.title_emb(batch_candidate_set)), \n",
    "                # self.desc_linear(self.desc_emb(batch_candidate_set)), \n",
    "                self.w2v_linear(self.w2v_emb(batch_candidate_set))\n",
    "            ], dim=-1)\n",
    "        else:\n",
    "            batch_candidate_set_emb = None\n",
    "        # # 对标签序列中的每个商品，获取它的嵌入表示并拼接\n",
    "        # batch_label_emb = torch.cat([\n",
    "        #     self.product_fea_emb[batch_label],  # 商品特征嵌入\n",
    "        #     self.title_linear(self.title_emb(batch_label)), \n",
    "        #     self.desc_linear(self.desc_emb(batch_label)), \n",
    "        #     self.w2v_linear(self.w2v_emb(batch_label))\n",
    "        # ], dim=-1)\n",
    "        # print(batch_prev_items_emb.shape, batch_candidate_set_emb.shape, batch_label_emb.shape)\n",
    "        return batch_prev_items_emb, batch_candidate_set_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntraAttention(nn.Module):\n",
    "    \"\"\"对轨迹经过 LSTM 后的隐藏层向量序列做 Attention 强化\n",
    "    key: 当前轨迹经过 LSTM 后的隐藏层向量序列\n",
    "    query: 轨迹向量序列的最后一个状态\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(IntraAttention, self).__init__()\n",
    "        # 模型参数\n",
    "        self.hidden_size = hidden_size\n",
    "        # 模型结构\n",
    "        self.w1 = nn.Linear(in_features=self.hidden_size, out_features=1, bias=False)\n",
    "        self.w2 = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size, bias=False)\n",
    "        self.w3 = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, query, key, mask=None):\n",
    "        \"\"\"前馈\n",
    "\n",
    "        Args:\n",
    "            query (tensor): shape (batch_size, hidden_size)\n",
    "            key (tensor): shape (batch_size, seq_len, hidden_size)\n",
    "            mask (tensor): padding mask, 1 表示非补齐值, 0 表示补齐值 shape (batch_size, seq_len)\n",
    "        Return:\n",
    "            attn_hidden (tensor): shape (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        attn_weight = torch.bmm(key, query.unsqueeze(2)).squeeze(2) # shape (batch_size, seq_len)\n",
    "        if mask is not None:\n",
    "            mask = attn_weight.masked_fill(mask==0, -1e9) # mask \n",
    "        attn_weight = torch.softmax(attn_weight, dim=1).unsqueeze(2) # shape (batch_size, seq_len, 1)\n",
    "        attn_hidden = torch.sum(attn_weight * key, dim=1)\n",
    "        return attn_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, products_input):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hid_dim\n",
    "        self.layers = layers\n",
    "        self.dropout = dropout\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.input_size = (products_encoded.shape[1] - 1) * self.emb_dim + 1 * 2 * self.emb_dim\n",
    "\n",
    "        self.product_emb = ProductEmbedding(products_input).to(device)\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.layers, batch_first=True)\n",
    "        self.intra_attn = IntraAttention(hidden_size=self.hidden_size)\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.output = nn.Linear(in_features=self.hidden_size, out_features=id_count)  # 所有的id的个数\n",
    "\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=100)  # 候选集大小100\n",
    "\n",
    "    def forward(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_prev_items: (B, len)\n",
    "            batch_locale: (B,)\n",
    "            batch_candidate_set: (B, 100)\n",
    "            batch_len: (B,)\n",
    "            batch_label: (B,)\n",
    "            batch_mask: (B, len)\n",
    "        \n",
    "        Return:\n",
    "            candidate_prob (tensor): 对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        batch_prev_items_emb, batch_candidate_set_emb = self.product_emb(batch_prev_items, None)\n",
    "        # batch_prev_items_emb (B, len, input_size)\n",
    "        # batch_candidate_set_emb (B, 100, input_size) or None\n",
    "\n",
    "        input_emb = self.dropout(batch_prev_items_emb)\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        if batch_mask is not None:\n",
    "            # LSTM with Mask\n",
    "            pack_input = pack_padded_sequence(input_emb, lengths=batch_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            pack_lstm_hidden, (hn, cn) = self.lstm(pack_input)\n",
    "            lstm_hidden, _ = pad_packed_sequence(pack_lstm_hidden, batch_first=True) # (B, len, hidden_size)\n",
    "        else:\n",
    "            lstm_hidden, (hn, cn) = self.lstm(input_emb) # (B, len, hidden_size)\n",
    "        \n",
    "        if batch_mask is not None:\n",
    "            # 获取序列最后一个非补齐值对应的 hidden\n",
    "            lstm_last_index = batch_len - 1 # (batch_size)\n",
    "            lstm_last_index = lstm_last_index.reshape(lstm_last_index.shape[0], 1, -1) # (B, 1, 1)\n",
    "            lstm_last_index = lstm_last_index.repeat(1, 1, self.hidden_size) # (B, 1, hidden_size)\n",
    "            lstm_last_hidden = torch.gather(lstm_hidden, dim=1, index=lstm_last_index).squeeze(1) # (B, hidden_size)\n",
    "        else:\n",
    "            lstm_last_hidden = lstm_hidden[:, -1, :] # (B, hidden_size)\n",
    "        attn_hidden = self.intra_attn(query=lstm_last_hidden, key=lstm_hidden, mask=batch_mask) # (B, hidden_size)\n",
    "        attn_hidden = self.dropout(attn_hidden) # (B, hidden_size)\n",
    "        \n",
    "        # 使用线性层直接预测\n",
    "        score = self.output(attn_hidden)  # (batch_size, id_count)\n",
    "        \n",
    "        # 根据 candidate_set 选出对应 candidate 的 score\n",
    "        candidate_score = torch.gather(score, dim=1, index=batch_candidate_set)  # (batch_size, candidate_count)\n",
    "        return candidate_score\n",
    "\n",
    "    def predict(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"预测\n",
    "        Return:\n",
    "            candidate_prob (tensor): softmax 后对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, False)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return torch.softmax(score, dim=1), loss\n",
    "\n",
    "    def calculate_loss(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            loss (tensor): 交叉损失熵 (1)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, True)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher(nn.Module):\n",
    "    \"\"\"Matcher 匹配打分\n",
    "    根据当前轨迹隐藏层表征与候选集表征之间计算一个匹配程度，也就是下一跳的评分\n",
    "\n",
    "    目前因为候选集表征与隐藏层表征维度不一样，所以对候选集表征过一个线性映射来计算。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, item_emb_size):\n",
    "        super(Matcher, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.item_emb_size = item_emb_size\n",
    "        self.linear = nn.Linear(in_features=self.item_emb_size, out_features=self.hidden_size)\n",
    "\n",
    "    def forward(self, items_hidden, candidate_emb):\n",
    "        \"\"\"前馈\n",
    "\n",
    "        Args:\n",
    "            items_hidden (tensor): 历史序列的隐藏层表征 (batch_size, hidden_size)\n",
    "            candidate_emb (tensor): 候选集表征 (batch_size, candidate_size, item_emb_size)\n",
    "        \"\"\"\n",
    "        candidate_hidden = self.linear(candidate_emb).permute(0, 2, 1) # (batch_size, hidden_size, candidate_size)\n",
    "        score = torch.bmm(items_hidden.unsqueeze(1), candidate_hidden).squeeze(1) # (batch_size, candidate_size)\n",
    "        return score\n",
    "\n",
    "\n",
    "class MatcherV2(nn.Module):\n",
    "    \"\"\"候选集与当前轨迹状态之间的注意力模块\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, item_emb_size, dropout):\n",
    "        super(MatcherV2, self).__init__()\n",
    "        self.out_linear = nn.Linear(in_features=hidden_size, out_features=1, bias=False)\n",
    "        self.w1_linear = nn.Linear(in_features=hidden_size, out_features=hidden_size, bias=False)\n",
    "        self.w2_linear = nn.Linear(in_features=item_emb_size, out_features=hidden_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        \"\"\"\n",
    "        计算 query 与 key 之间的相似度\n",
    "        计算方法为可学习前馈神经网络：attn_weight = w_out * tanh(w_1 * query + w_2 * key)\n",
    "        Args:\n",
    "            query: 历史序列的隐藏层表征 shape: (batch_size, hidden_size)\n",
    "            key: 候选集的嵌入向量 shape: (batch_size, candidate_size, item_emb_size)\n",
    "            hidden_size = item_emb_size\n",
    "\n",
    "        Returns:\n",
    "            candidate_weight: 当前状态与候选集之间的相关性向量。shape: (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        query_hidden = torch.relu(self.w1_linear(query).unsqueeze(1))  # shape: (batch_size, 1, hidden_size)\n",
    "        key_hidden = torch.relu(self.w2_linear(key))  # shape: (batch_size, candidate_size, hidden_size)\n",
    "        candidate_weight = torch.tanh(query_hidden + key_hidden)  # shape: (batch_size, candidate_size, hidden_size)\n",
    "        candidate_weight = self.dropout(candidate_weight)\n",
    "        out = self.out_linear(candidate_weight).squeeze(2)  # shape: (batch_size, candidate_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchModel(nn.Module):\n",
    "\n",
    "    def __init__(self, products_input):\n",
    "        super(MatchModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hid_dim\n",
    "        self.layers = layers\n",
    "        self.dropout_p = dropout\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.input_size = (products_encoded.shape[1] - 1) * self.emb_dim + 1 * 2 * self.emb_dim\n",
    "\n",
    "        self.product_emb = ProductEmbedding(products_input).to(device)\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.layers, batch_first=True)\n",
    "        self.intra_attn = IntraAttention(hidden_size=self.hidden_size)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        if atten_match:\n",
    "            self.output = MatcherV2(hidden_size=self.hidden_size, item_emb_size=self.input_size, dropout=self.dropout_p)\n",
    "        else:\n",
    "            self.output = Matcher(hidden_size=self.hidden_size, item_emb_size=self.input_size)\n",
    "\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=100)  # 候选集大小100\n",
    "\n",
    "    def forward(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_prev_items: (B, len)\n",
    "            batch_locale: (B,)\n",
    "            batch_candidate_set: (B, 100)\n",
    "            batch_len: (B,)\n",
    "            batch_label: (B,)\n",
    "            batch_mask: (B, len)\n",
    "        \n",
    "        Return:\n",
    "            candidate_prob (tensor): 对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        batch_prev_items_emb, batch_candidate_set_emb = self.product_emb(batch_prev_items, batch_candidate_set)\n",
    "        # batch_prev_items_emb (B, len, input_size)\n",
    "        # batch_candidate_set_emb (B, 100, input_size) or None\n",
    "\n",
    "        input_emb = self.dropout(batch_prev_items_emb)\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        if batch_mask is not None:\n",
    "            # LSTM with Mask\n",
    "            pack_input = pack_padded_sequence(input_emb, lengths=batch_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            pack_lstm_hidden, (hn, cn) = self.lstm(pack_input)\n",
    "            lstm_hidden, _ = pad_packed_sequence(pack_lstm_hidden, batch_first=True) # (B, len, hidden_size)\n",
    "        else:\n",
    "            lstm_hidden, (hn, cn) = self.lstm(input_emb) # (B, len, hidden_size)\n",
    "        \n",
    "        if batch_mask is not None:\n",
    "            # 获取序列最后一个非补齐值对应的 hidden\n",
    "            lstm_last_index = batch_len - 1 # (batch_size)\n",
    "            lstm_last_index = lstm_last_index.reshape(lstm_last_index.shape[0], 1, -1) # (B, 1, 1)\n",
    "            lstm_last_index = lstm_last_index.repeat(1, 1, self.hidden_size) # (B, 1, hidden_size)\n",
    "            lstm_last_hidden = torch.gather(lstm_hidden, dim=1, index=lstm_last_index).squeeze(1) # (B, hidden_size)\n",
    "        else:\n",
    "            lstm_last_hidden = lstm_hidden[:, -1, :] # (B, hidden_size)\n",
    "        attn_hidden = self.intra_attn(query=lstm_last_hidden, key=lstm_hidden, mask=batch_mask) # (B, hidden_size)\n",
    "        attn_hidden = self.dropout(attn_hidden) # (B, hidden_size)\n",
    "        \n",
    "        # Matcher\n",
    "        candidate_score = self.output(attn_hidden, batch_candidate_set_emb)  # (batch_size, candidate_size)\n",
    "        return candidate_score\n",
    "\n",
    "    def predict(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"预测\n",
    "        Return:\n",
    "            candidate_prob (tensor): softmax 后对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, False)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return torch.softmax(score, dim=1), loss\n",
    "\n",
    "    def calculate_loss(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            loss (tensor): 交叉损失熵 (1)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, True)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 16\n",
    "dense_bins = 10\n",
    "hid_dim = 256\n",
    "dropout = 0.5\n",
    "layers = 4\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "lr_patience = 5\n",
    "lr_decay_ratio = 0.1\n",
    "clip = 5\n",
    "batch_size = 512 * 2\n",
    "epochs = 30\n",
    "log_every = 100\n",
    "early_stop = True\n",
    "patience = 10\n",
    "kfold = 5\n",
    "device = torch.device('cuda:2')\n",
    "atten_match = True \n",
    "\n",
    "w2v_window = 3\n",
    "w2v_min_count = 1\n",
    "w2v_epochs = 500\n",
    "w2v_vector_size = 128\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    \"\"\"\n",
    "    重置随机数种子\n",
    "\n",
    "    Args:\n",
    "        seed(int): 种子数\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'BaseModel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_input = {name: torch.tensor(products_encoded[name].values).to(device) for name in products_encoded.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "model = BaseModel(products_input).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=lr_patience, factor=lr_decay_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (product_emb): ProductEmbedding(\n",
       "    (product_fea): Product(\n",
       "      (locale_emb): Embedding(6, 16)\n",
       "      (price_emb): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (len_title_emb): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (len_desc_emb): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (encode_brand_emb): Embedding(177190, 16)\n",
       "      (encode_color_emb): Embedding(203261, 16)\n",
       "      (encode_size_emb): Embedding(218061, 16)\n",
       "      (encode_model_emb): Embedding(524102, 16)\n",
       "      (encode_material_emb): Embedding(45569, 16)\n",
       "      (encode_author_emb): Embedding(30836, 16)\n",
       "      (encode_price_emb): Embedding(10, 16)\n",
       "      (encode_len_title_emb): Embedding(10, 16)\n",
       "      (encode_len_desc_emb): Embedding(10, 16)\n",
       "    )\n",
       "    (w2v_emb): Embedding(1410676, 128, padding_idx=1410675)\n",
       "    (w2v_linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "  )\n",
       "  (lstm): LSTM(240, 256, num_layers=4, batch_first=True)\n",
       "  (intra_attn): IntraAttention(\n",
       "    (w1): Linear(in_features=256, out_features=1, bias=False)\n",
       "    (w2): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (w3): Linear(in_features=256, out_features=256, bias=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (output): Linear(in_features=256, out_features=1410675, bias=True)\n",
       "  (loss_func): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_emb.product_fea.locale_emb.weight\ttorch.Size([6, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.price_emb.weight\ttorch.Size([16, 1])\tcuda:2\tTrue\n",
      "product_emb.product_fea.price_emb.bias\ttorch.Size([16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_title_emb.weight\ttorch.Size([16, 1])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_title_emb.bias\ttorch.Size([16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_desc_emb.weight\ttorch.Size([16, 1])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_desc_emb.bias\ttorch.Size([16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_brand_emb.weight\ttorch.Size([177190, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_color_emb.weight\ttorch.Size([203261, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_size_emb.weight\ttorch.Size([218061, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_model_emb.weight\ttorch.Size([524102, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_material_emb.weight\ttorch.Size([45569, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_author_emb.weight\ttorch.Size([30836, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_price_emb.weight\ttorch.Size([10, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_len_title_emb.weight\ttorch.Size([10, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_len_desc_emb.weight\ttorch.Size([10, 16])\tcuda:2\tTrue\n",
      "product_emb.w2v_emb.weight\ttorch.Size([1410676, 128])\tcuda:2\tTrue\n",
      "product_emb.w2v_linear.weight\ttorch.Size([32, 128])\tcuda:2\tTrue\n",
      "product_emb.w2v_linear.bias\ttorch.Size([32])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l0\ttorch.Size([1024, 240])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l0\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l0\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l0\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l1\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l1\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l1\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l1\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l2\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l2\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l2\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l2\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l3\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l3\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l3\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l3\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "intra_attn.w1.weight\ttorch.Size([1, 256])\tcuda:2\tTrue\n",
      "intra_attn.w2.weight\ttorch.Size([256, 256])\tcuda:2\tTrue\n",
      "intra_attn.w3.weight\ttorch.Size([256, 256])\tcuda:2\tTrue\n",
      "output.weight\ttorch.Size([1410675, 256])\tcuda:2\tTrue\n",
      "output.bias\ttorch.Size([1410675])\tcuda:2\tTrue\n",
      "564519395\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(str(name) + '\\t' + str(param.shape) + '\\t' +\n",
    "                              str(param.device) + '\\t' + str(param.requires_grad))\n",
    "total_num = sum([param.nelement() for param in model.parameters()])\n",
    "print(total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(len(df_train_encoded) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = NNDataset(df_train_encoded[:train_split], product2id)\n",
    "val_set = NNDataset(df_train_encoded[train_split:], product2id)\n",
    "test_set = NNDataset(df_test_encoded, product2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2818, 705, 310)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train model:   0%|          | 0/2818 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.35 GiB (GPU 2; 23.70 GiB total capacity; 19.72 GiB already allocated; 502.56 MiB free; 21.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2f1502adf37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.35 GiB (GPU 2; 23.70 GiB total capacity; 19.72 GiB already allocated; 502.56 MiB free; 21.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "ac_all = []\n",
    "mrr_all = []\n",
    "min_val_loss = float('inf')\n",
    "max_val_acc = 0.0\n",
    "best_epoch = -1\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    print('start train epoch {}'.format(epoch))\n",
    "    model.train()\n",
    "    train_loss_list = []\n",
    "    for batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, _, batch_label_index in tqdm(train_loader, desc='train model'):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.calculate_loss(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n",
    "                                        batch_candidate_set=batch_candidate_set, batch_len=batch_len, \n",
    "                                        batch_label=batch_label_index, batch_mask=batch_mask)\n",
    "        loss.backward(retain_graph=True)\n",
    "        train_loss_list.append(loss.item())\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    train_loss = np.mean(train_loss_list)\n",
    "    # val\n",
    "    val_hit = 0\n",
    "    val_loss_list= []\n",
    "    mrr = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index in tqdm(val_loader, desc='val model'):\n",
    "            score, loss = model.predict(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n",
    "                                        batch_candidate_set=batch_candidate_set, batch_len=batch_len, \n",
    "                                        batch_label=batch_label_index, batch_mask=batch_mask)  # (batch_size, candidate_size)\n",
    "            val_loss_list.append(loss.item())\n",
    "            val_hit += score.argmax(dim=-1).eq(batch_label_index).sum().item()\n",
    "            sorted_indices = torch.argsort(score, dim=1, descending=True)\n",
    "            sorted_candidate_set = batch_candidate_set.gather(dim=1, index=sorted_indices)\n",
    "            for i in range(len(sorted_candidate_set)):\n",
    "                pred = sorted_candidate_set[i].tolist()\n",
    "                try:\n",
    "                    pred_result = pred.index(batch_label[i].item())\n",
    "                    mrr.append(1 / (pred_result + 1))\n",
    "                except:\n",
    "                    mrr.append(0)\n",
    "    val_ac = val_hit / len(val_set)\n",
    "    val_loss = np.mean(val_loss_list)\n",
    "    val_mrr = np.mean(mrr)\n",
    "    mrr_all += mrr\n",
    "    ac_all.append(val_ac)\n",
    "    lr_scheduler.step(val_ac)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print('Train Epoch {}: Train Loss {:.6f}, Val Loss {:.6f}, Val AC {:.6f}, Val MRR {:.6f}, lr {}'.format(epoch, train_loss, val_loss, val_ac, val_mrr, lr))\n",
    "    if val_ac > max_val_acc:\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), 'ckpt/{}_{}.pt'.format(model_name, epoch))\n",
    "        min_val_loss = val_loss\n",
    "        max_val_acc = val_ac\n",
    "        best_epoch = epoch\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait == patience and early_stop:\n",
    "            print('Early stopping at epoch: %d' % epoch)\n",
    "            break\n",
    "print('Val MRR {}'.format(np.mean(mrr_all)))\n",
    "print('Val ACC {}'.format(np.mean(ac_all)))\n",
    "# load best epoch\n",
    "print('load best from {}'.format(best_epoch))\n",
    "print('min_val_loss {}, max_val_acc {}.'.format(min_val_loss, max_val_acc))\n",
    "model.load_state_dict(torch.load('ckpt/{}_{}.pt'.format(model_name, best_epoch)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本地测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test model:   0%|          | 6/79243 [00:13<49:02:34,  2.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-8f01a40b4296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_prev_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_locale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     score, loss = model.predict(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n\u001b[0m\u001b[1;32m      7\u001b[0m                                     \u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     batch_label=batch_label_index, batch_mask=batch_mask)  # (batch_size, 100)\n",
      "\u001b[0;32m<ipython-input-25-57fa92e0948f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mcandidate_prob\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0m后对候选集下一跳的概率预测\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_prev_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_locale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-57fa92e0948f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, train)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mcandidate_prob\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m对候选集下一跳的概率预测\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \"\"\"\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mbatch_prev_items_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_candidate_set_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_prev_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# batch_prev_items_emb (B, len, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# batch_candidate_set_emb (B, 100, input_size) or None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-45d0549ebf11>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_prev_items, batch_candidate_set)\u001b[0m\n\u001b[1;32m     39\u001b[0m             batch_candidate_set_emb = torch.cat([\n\u001b[1;32m     40\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct_fea_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 商品特征嵌入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2v_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始评估\n",
    "test_scores = []\n",
    "test_res = []\n",
    "model.eval()\n",
    "for batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, _, _ in tqdm(test_loader, desc='test model'):\n",
    "    score, loss = model.predict(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n",
    "                                    batch_candidate_set=batch_candidate_set, batch_len=batch_len, \n",
    "                                    batch_label=batch_label_index, batch_mask=batch_mask)  # (batch_size, 100)\n",
    "    test_scores.append(score.cpu().numpy())\n",
    "    sorted_indices = torch.argsort(score, dim=1, descending=True)\n",
    "    sorted_candidate_set = batch_candidate_set.gather(dim=1, index=sorted_indices)  # (B, 100)\n",
    "    test_res.append(sorted_candidate_set.cpu().numpy())\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), './ckpt/{}.pt'.format(model_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1111"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
