{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cab\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "import json \n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import sentence_transformers \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B09W9FND7K' 'B09JSPLN1M']</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606244</th>\n",
       "      <td>['B086CYFSKW' 'B0874F9859' 'B086CYFSKW']</td>\n",
       "      <td>B07B5TYD76</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606245</th>\n",
       "      <td>['B09NRZKZ7V' 'B08WJTPV93']</td>\n",
       "      <td>B08L1P4C3D</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606246</th>\n",
       "      <td>['B085JFX7MP' 'B085JGHW8R']</td>\n",
       "      <td>B01MPWVD44</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606247</th>\n",
       "      <td>['B00B0UING2' 'B00B0UING2']</td>\n",
       "      <td>B00D3HYEZ4</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606248</th>\n",
       "      <td>['B092S9D1SD' 'B09XQQ1S72' 'B0852MS7QC' 'B0B1V...</td>\n",
       "      <td>B0B7RX65YP</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3606249 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prev_items   next_item locale\n",
       "0                              ['B09W9FND7K' 'B09JSPLN1M']  B09M7GY217     DE\n",
       "1        ['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...  B001B4THSA     DE\n",
       "2        ['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...  B0767DTG2Q     DE\n",
       "3        ['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...  B0B4R9NN4B     DE\n",
       "4                 ['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']  B0BGVBKWGZ     DE\n",
       "...                                                    ...         ...    ...\n",
       "3606244           ['B086CYFSKW' 'B0874F9859' 'B086CYFSKW']  B07B5TYD76     IT\n",
       "3606245                        ['B09NRZKZ7V' 'B08WJTPV93']  B08L1P4C3D     IT\n",
       "3606246                        ['B085JFX7MP' 'B085JGHW8R']  B01MPWVD44     IT\n",
       "3606247                        ['B00B0UING2' 'B00B0UING2']  B00D3HYEZ4     IT\n",
       "3606248  ['B092S9D1SD' 'B09XQQ1S72' 'B0852MS7QC' 'B0B1V...  B0B7RX65YP     IT\n",
       "\n",
       "[3606249 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3606249, 3)\n",
    "df_train = pd.read_csv('data/sessions_train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B08KQBYV43' '3955350843' '3955350843' '39553...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316966</th>\n",
       "      <td>['B077SZ2C3Y' 'B0B14M3VZX']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316967</th>\n",
       "      <td>['B08KFHDPY9' 'B0851KTSRZ' 'B08KFHDPY9' 'B0851...</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316968</th>\n",
       "      <td>['B07PY1N81F' 'B07Q1Z8SQN' 'B07PY1N81F' 'B07Q1...</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316969</th>\n",
       "      <td>['B01MCQMORK' 'B09JYZ325W']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316970</th>\n",
       "      <td>['B0B8JX92YJ' 'B09TN4MP6V' 'B0BG2LZQSL']</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316971 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prev_items locale\n",
       "0       ['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...     DE\n",
       "1                ['B00R9R5ND6' 'B00R9RZ9ZS' 'B00R9RZ9ZS']     DE\n",
       "2       ['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK' 'B07G7...     DE\n",
       "3       ['B08KQBYV43' '3955350843' '3955350843' '39553...     DE\n",
       "4       ['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...     DE\n",
       "...                                                   ...    ...\n",
       "316966                        ['B077SZ2C3Y' 'B0B14M3VZX']     UK\n",
       "316967  ['B08KFHDPY9' 'B0851KTSRZ' 'B08KFHDPY9' 'B0851...     UK\n",
       "316968  ['B07PY1N81F' 'B07Q1Z8SQN' 'B07PY1N81F' 'B07Q1...     UK\n",
       "316969                        ['B01MCQMORK' 'B09JYZ325W']     UK\n",
       "316970           ['B0B8JX92YJ' 'B09TN4MP6V' 'B0BG2LZQSL']     UK\n",
       "\n",
       "[316971 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (316971, 2)\n",
    "df_test = pd.read_csv('data/sessions_test_task1.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(x):\n",
    "    x = x.replace('[', '').replace(']', '').replace(\"'\", '').replace('\\n', ' ').replace('\\r', ' ')\n",
    "    l = [i for i in x.split() if i]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1min多一些\n",
    "df_train['prev_items'] = df_train['prev_items'].apply(lambda x: str2list(x))\n",
    "df_test['prev_items'] = df_test['prev_items'].apply(lambda x: str2list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B09W9FND7K, B09JSPLN1M]</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606244</th>\n",
       "      <td>[B086CYFSKW, B0874F9859, B086CYFSKW]</td>\n",
       "      <td>B07B5TYD76</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606245</th>\n",
       "      <td>[B09NRZKZ7V, B08WJTPV93]</td>\n",
       "      <td>B08L1P4C3D</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606246</th>\n",
       "      <td>[B085JFX7MP, B085JGHW8R]</td>\n",
       "      <td>B01MPWVD44</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606247</th>\n",
       "      <td>[B00B0UING2, B00B0UING2]</td>\n",
       "      <td>B00D3HYEZ4</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606248</th>\n",
       "      <td>[B092S9D1SD, B09XQQ1S72, B0852MS7QC, B0B1V43MN1]</td>\n",
       "      <td>B0B7RX65YP</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3606249 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prev_items   next_item locale\n",
       "0                                 [B09W9FND7K, B09JSPLN1M]  B09M7GY217     DE\n",
       "1         [B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]  B001B4THSA     DE\n",
       "2        [B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...  B0767DTG2Q     DE\n",
       "3        [B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...  B0B4R9NN4B     DE\n",
       "4                     [B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]  B0BGVBKWGZ     DE\n",
       "...                                                    ...         ...    ...\n",
       "3606244               [B086CYFSKW, B0874F9859, B086CYFSKW]  B07B5TYD76     IT\n",
       "3606245                           [B09NRZKZ7V, B08WJTPV93]  B08L1P4C3D     IT\n",
       "3606246                           [B085JFX7MP, B085JGHW8R]  B01MPWVD44     IT\n",
       "3606247                           [B00B0UING2, B00B0UING2]  B00D3HYEZ4     IT\n",
       "3606248   [B092S9D1SD, B09XQQ1S72, B0852MS7QC, B0B1V43MN1]  B0B7RX65YP     IT\n",
       "\n",
       "[3606249 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['last_item'] = df_train['prev_items'].apply(lambda x: x[-1])\n",
    "df_test['last_item'] = df_test['prev_items'].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3606249, 4), (316971, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc2id = {\n",
    "    'DE': 0,\n",
    "    'JP': 1,\n",
    "    'UK': 2,\n",
    "    'ES': 3,\n",
    "    'FR': 4,\n",
    "    'IT': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.load('data/train_ids.npy')\n",
    "test_ids = np.load('data/test_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338847"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ids = set(train_ids) | set(test_ids)\n",
    "len(total_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "产品特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verfügbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Geräte mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【Auto aufziehbar】: Drücken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 Stück</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551052</th>\n",
       "      <td>B09BW5CDRR</td>\n",
       "      <td>IT</td>\n",
       "      <td>Barbie - Playset Gelateria con Bambola con Mac...</td>\n",
       "      <td>20.48</td>\n",
       "      <td>Barbie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DETTAGLI REALISTICI. Basta inserire la pasta m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551053</th>\n",
       "      <td>B0050IILBM</td>\n",
       "      <td>IT</td>\n",
       "      <td>Braun Silk-épil 1 Depilatore Donna, Epilatore ...</td>\n",
       "      <td>22.61</td>\n",
       "      <td>Braun</td>\n",
       "      <td>Pink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4210201656067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alimentato a corrente per un comodo utilizzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551054</th>\n",
       "      <td>B07W4C5W9D</td>\n",
       "      <td>IT</td>\n",
       "      <td>BoxLegend Sacchetti Sottovuoto Vestiti 6 Pezzi...</td>\n",
       "      <td>14.99</td>\n",
       "      <td>BoxLegend</td>\n",
       "      <td>6 Pezzi.</td>\n",
       "      <td>6 Pezzi (2L + 2M + 2S)</td>\n",
       "      <td>6186666487608_SML</td>\n",
       "      <td>Polietilene Ppa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 Sacchetti in 3 Diverse Misure- Questo set di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551055</th>\n",
       "      <td>B012D0HJXA</td>\n",
       "      <td>IT</td>\n",
       "      <td>Trasportino Pratiko Metal - Accessorio da viag...</td>\n",
       "      <td>18.35</td>\n",
       "      <td>MPS</td>\n",
       "      <td>verde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metallo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRASPORTINO 48X31.5X33CM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551056</th>\n",
       "      <td>B07P5RLXP3</td>\n",
       "      <td>IT</td>\n",
       "      <td>LiCB - Batterie LR1130, batterie alcaline AG10...</td>\n",
       "      <td>6.99</td>\n",
       "      <td>LiCB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 Stück LR1130</td>\n",
       "      <td>LR1130-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denominazione: 20 pezzi di pile alcaline LR113...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1551057 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id locale                                              title  \\\n",
       "0        B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1        B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2        B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3        B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4        B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "...             ...    ...                                                ...   \n",
       "1551052  B09BW5CDRR     IT  Barbie - Playset Gelateria con Bambola con Mac...   \n",
       "1551053  B0050IILBM     IT  Braun Silk-épil 1 Depilatore Donna, Epilatore ...   \n",
       "1551054  B07W4C5W9D     IT  BoxLegend Sacchetti Sottovuoto Vestiti 6 Pezzi...   \n",
       "1551055  B012D0HJXA     IT  Trasportino Pratiko Metal - Accessorio da viag...   \n",
       "1551056  B07P5RLXP3     IT  LiCB - Batterie LR1130, batterie alcaline AG10...   \n",
       "\n",
       "         price         brand              color                    size  \\\n",
       "0        30.95    RED DRAGON                NaN                     NaN   \n",
       "1        17.90   Simply Keto                NaN        750 g (1er Pack)   \n",
       "2        68.89    Sennheiser       Multi-Colour                One size   \n",
       "3        18.99  Amy & Benton         Animal Car                     NaN   \n",
       "4         7.17     PLAYMOBIL  Nicht Zutreffend.                 OneSize   \n",
       "...        ...           ...                ...                     ...   \n",
       "1551052  20.48        Barbie                NaN                     NaN   \n",
       "1551053  22.61         Braun               Pink                     NaN   \n",
       "1551054  14.99     BoxLegend           6 Pezzi.  6 Pezzi (2L + 2M + 2S)   \n",
       "1551055  18.35           MPS              verde                     NaN   \n",
       "1551056   6.99          LiCB                NaN         20 Stück LR1130   \n",
       "\n",
       "                     model            material author  \\\n",
       "0                  RDD0089                 NaN    NaN   \n",
       "1                      NaN                 NaN    NaN   \n",
       "2                   508377          Kunstleder    NaN   \n",
       "3                    2008B  aufziehauto 1 jahr    NaN   \n",
       "4                    70522        Polypropylen    NaN   \n",
       "...                    ...                 ...    ...   \n",
       "1551052              HCN46                 NaN    NaN   \n",
       "1551053      4210201656067                 NaN    NaN   \n",
       "1551054  6186666487608_SML     Polietilene Ppa    NaN   \n",
       "1551055                NaN             Metallo    NaN   \n",
       "1551056          LR1130-20                 NaN    NaN   \n",
       "\n",
       "                                                      desc  \n",
       "0        Amberjacks Steel Dartpfeile sind verfügbar in ...  \n",
       "1        🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2        3.5 MM BUCHSE - Kann problemlos an Geräte mit ...  \n",
       "3        【Auto aufziehbar】: Drücken Sie einfach leicht ...  \n",
       "4                                          Inhalt: 1 Stück  \n",
       "...                                                    ...  \n",
       "1551052  DETTAGLI REALISTICI. Basta inserire la pasta m...  \n",
       "1551053       Alimentato a corrente per un comodo utilizzo  \n",
       "1551054  6 Sacchetti in 3 Diverse Misure- Questo set di...  \n",
       "1551055                           TRASPORTINO 48X31.5X33CM  \n",
       "1551056  Denominazione: 20 pezzi di pile alcaline LR113...  \n",
       "\n",
       "[1551057 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不到1min (1551057, 11)\n",
    "products = pd.read_csv('data/products_train.csv')\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verfügbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Geräte mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【Auto aufziehbar】: Drücken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 Stück</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id locale                                              title  \\\n",
       "0  B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "   price         brand              color              size    model  \\\n",
       "0  30.95    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.90   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.89    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.99  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.17     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  \\\n",
       "0                 NaN    NaN   \n",
       "1                 NaN    NaN   \n",
       "2          Kunstleder    NaN   \n",
       "3  aufziehauto 1 jahr    NaN   \n",
       "4        Polypropylen    NaN   \n",
       "\n",
       "                                                desc  \n",
       "0  Amberjacks Steel Dartpfeile sind verfügbar in ...  \n",
       "1  🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2  3.5 MM BUCHSE - Kann problemlos an Geräte mit ...  \n",
       "3  【Auto aufziehbar】: Drücken Sie einfach leicht ...  \n",
       "4                                    Inhalt: 1 Stück  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_ids = products['id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410675"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ids = len(products_ids)\n",
    "\n",
    "len_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以把训练lgb的那些聚合出来的序列特征，比如平均价格之类的，MLP之后拼接到RNN的输出，一起做预测之类的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = products[products.duplicated(subset=['id'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = duplicated_rows.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows.to_csv('data/duplicated_products.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410675, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.drop_duplicates(subset=['id'], keep='first', inplace=True)\n",
    "products.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verfügbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Geräte mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【Auto aufziehbar】: Drücken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 Stück</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id locale                                              title  \\\n",
       "0  B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "   price         brand              color              size    model  \\\n",
       "0  30.95    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.90   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.89    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.99  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.17     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  \\\n",
       "0                 NaN    NaN   \n",
       "1                 NaN    NaN   \n",
       "2          Kunstleder    NaN   \n",
       "3  aufziehauto 1 jahr    NaN   \n",
       "4        Polypropylen    NaN   \n",
       "\n",
       "                                                desc  \n",
       "0  Amberjacks Steel Dartpfeile sind verfügbar in ...  \n",
       "1  🌱 NATÜRLICHE SÜSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2  3.5 MM BUCHSE - Kann problemlos an Geräte mit ...  \n",
       "3  【Auto aufziehbar】: Drücken Sie einfach leicht ...  \n",
       "4                                    Inhalt: 1 Stück  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['len_title'] = products['title'].apply(lambda x : 0 if type(x) == float else len(x))\n",
    "products['len_desc'] = products['desc'].apply(lambda x : 0 if type(x) == float else len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'locale', 'title', 'price', 'brand', 'color', 'size', 'model',\n",
       "       'material', 'author', 'desc', 'len_title', 'len_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['brand', 'color', 'size', 'model', 'material', 'author']\n",
    "num_features = ['price', 'len_title', 'len_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    products['encode_' + f] = le.fit_transform(products[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_bins = 10\n",
    "add_cat_features = []\n",
    "for f in num_features:\n",
    "    discretizer = KBinsDiscretizer(n_bins=dense_bins, encode='ordinal', strategy='kmeans')  # 等频quantile，等宽uniform\n",
    "    products['encode_' + f] = discretizer.fit_transform(np.array(products[f].tolist()).reshape(-1, 1))\n",
    "    add_cat_features.append('encode_' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fe in add_cat_features:\n",
    "    products[fe] = products[fe].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['price', 'len_title', 'len_desc']\n",
    "for fe in num_features:\n",
    "    products[fe] = products[fe].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encode_price', 'encode_len_title', 'encode_len_desc']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_model.to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = products['title'].values\n",
    "titles_embedding = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = products['desc'].values\n",
    "descs_embedding = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [2:11:56<00:00, 178.20it/s] \n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(titles, total=len(titles)):\n",
    "    if type(s) == float:\n",
    "        titles_embedding.append(np.zeros(titles_embedding[-1].shape))\n",
    "    else:\n",
    "        titles_embedding.append(sentence_model.encode(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [2:03:08<00:00, 190.93it/s] \n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(descs, total=len(descs)):\n",
    "    if type(s) == float:\n",
    "        descs_embedding.append(np.zeros(descs_embedding[-1].shape))\n",
    "    else:\n",
    "        descs_embedding.append(sentence_model.encode(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/titles_embedding.npy', titles_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/descs_embedding.npy', descs_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1410675, 384), (1410675, 384))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_embedding = np.load('./data/titles_embedding.npy')\n",
    "descs_embedding = np.load('./data/descs_embedding.npy')\n",
    "titles_embedding.shape, descs_embedding.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['locale'] = products['locale'].apply(lambda x: loc2id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>...</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>0</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>0</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>0</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>0</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>0</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  locale                                              title  \\\n",
       "0  B005ZSSN10       0  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD       0  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V       0  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S       0  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D       0      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "       price         brand              color              size    model  \\\n",
       "0  30.950001    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.900000   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.889999    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.990000  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.170000     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  ... len_desc  encode_brand  encode_color  \\\n",
       "0                 NaN    NaN  ...    121.0        112134        203260   \n",
       "1                 NaN    NaN  ...    330.0        124505        203260   \n",
       "2          Kunstleder    NaN  ...     95.0        122979        114264   \n",
       "3  aufziehauto 1 jahr    NaN  ...    191.0          9834         46931   \n",
       "4        Polypropylen    NaN  ...     15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410675, 22)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [f for f in products.columns if f not in ['title', 'desc'] + cat_features]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_csv('./data/products_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551041</th>\n",
       "      <td>B09XN5CXDM</td>\n",
       "      <td>5</td>\n",
       "      <td>578.979980</td>\n",
       "      <td>124.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>116789</td>\n",
       "      <td>55013</td>\n",
       "      <td>109396</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551044</th>\n",
       "      <td>B09S3KGLG6</td>\n",
       "      <td>5</td>\n",
       "      <td>43.490002</td>\n",
       "      <td>195.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>121227</td>\n",
       "      <td>80328</td>\n",
       "      <td>143053</td>\n",
       "      <td>524101</td>\n",
       "      <td>19188</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551046</th>\n",
       "      <td>B00E4L5YPW</td>\n",
       "      <td>5</td>\n",
       "      <td>8.410000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52556</td>\n",
       "      <td>39304</td>\n",
       "      <td>6470</td>\n",
       "      <td>257247</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551047</th>\n",
       "      <td>B08B4DFWCR</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>23342</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>57350</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551055</th>\n",
       "      <td>B012D0HJXA</td>\n",
       "      <td>5</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>113.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>89982</td>\n",
       "      <td>170638</td>\n",
       "      <td>218060</td>\n",
       "      <td>524101</td>\n",
       "      <td>18060</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1410675 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  locale       price  len_title  len_desc  encode_brand  \\\n",
       "0        B005ZSSN10       0   30.950001       96.0     121.0        112134   \n",
       "1        B08PRYN6LD       0   17.900000      186.0     330.0        124505   \n",
       "2        B09MBZJ48V       0   68.889999      181.0      95.0        122979   \n",
       "3        B08ZN6F26S       0   18.990000      101.0     191.0          9834   \n",
       "4        B094DGRV7D       0    7.170000       45.0      15.0        105135   \n",
       "...             ...     ...         ...        ...       ...           ...   \n",
       "1551041  B09XN5CXDM       5  578.979980      124.0     250.0        116789   \n",
       "1551044  B09S3KGLG6       5   43.490002      195.0     479.0        121227   \n",
       "1551046  B00E4L5YPW       5    8.410000      144.0      57.0         52556   \n",
       "1551047  B08B4DFWCR       5  100.000000       59.0      85.0         23342   \n",
       "1551055  B012D0HJXA       5   18.350000      113.0      24.0         89982   \n",
       "\n",
       "         encode_color  encode_size  encode_model  encode_material  \\\n",
       "0              203260       218060        426630            45568   \n",
       "1              203260       128007        524101            45568   \n",
       "2              114264       170270        145013            15566   \n",
       "3               46931       218060         67408            29357   \n",
       "4              117844       170305        174527            23064   \n",
       "...               ...          ...           ...              ...   \n",
       "1551041         55013       109396        524101            45568   \n",
       "1551044         80328       143053        524101            19188   \n",
       "1551046         39304         6470        257247            45568   \n",
       "1551047        203260       218060         57350            45568   \n",
       "1551055        170638       218060        524101            18060   \n",
       "\n",
       "         encode_author  encode_price  encode_len_title  encode_len_desc  \n",
       "0                30835             0                 2                2  \n",
       "1                30835             0                 4                5  \n",
       "2                30835             0                 4                1  \n",
       "3                30835             0                 2                3  \n",
       "4                30835             0                 0                0  \n",
       "...                ...           ...               ...              ...  \n",
       "1551041          30835             0                 2                4  \n",
       "1551044          30835             0                 4                7  \n",
       "1551046          30835             0                 3                1  \n",
       "1551047          30835             0                 1                1  \n",
       "1551055          30835             0                 2                0  \n",
       "\n",
       "[1410675 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'locale', 'title', 'price', 'brand', 'color', 'size', 'model',\n",
       "       'material', 'author', 'desc', 'len_title', 'len_desc', 'encode_brand',\n",
       "       'encode_color', 'encode_size', 'encode_model', 'encode_material',\n",
       "       'encode_author', 'encode_price', 'encode_len_title', 'encode_len_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  1410675\n",
       "locale                    6\n",
       "title               1360094\n",
       "price                 37608\n",
       "brand                177189\n",
       "color                203260\n",
       "size                 218060\n",
       "model                524101\n",
       "material              45568\n",
       "author                30835\n",
       "desc                 800044\n",
       "len_title               480\n",
       "len_desc                763\n",
       "encode_brand         177190\n",
       "encode_color         203261\n",
       "encode_size          218061\n",
       "encode_model         524102\n",
       "encode_material       45569\n",
       "encode_author         30836\n",
       "encode_price             10\n",
       "encode_len_title         10\n",
       "encode_len_desc          10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [00:01<00:00, 1173467.39it/s]\n"
     ]
    }
   ],
   "source": [
    "product2id = {}\n",
    "id2product = {}\n",
    "\n",
    "for ind, id_ in enumerate(tqdm(products['id'].values, total=len(products['id']))):\n",
    "    product2id[id_] = ind\n",
    "    id2product[ind] = id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(product2id, open('data/product2id.json', 'w'))\n",
    "json.dump(id2product, open('data/id2product.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2id = json.load(open('data/product2id.json', 'r'))\n",
    "id2product = json.load(open('data/id2product.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2product = {int(k): v for k, v in id2product.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3606249, 4), (316971, 3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B099NQFMG7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B00R9RZ9ZS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B07G7Q5N6G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B08KQBYV43, 3955350843, 3955350843, 395535086...</td>\n",
       "      <td>DE</td>\n",
       "      <td>3955350843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09J945WQR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items locale   last_item\n",
       "0  [B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...     DE  B099NQFMG7\n",
       "1               [B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]     DE  B00R9RZ9ZS\n",
       "2   [B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]     DE  B07G7Q5N6G\n",
       "3  [B08KQBYV43, 3955350843, 3955350843, 395535086...     DE  3955350843\n",
       "4  [B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...     DE  B09J945WQR"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_encoded = df_test.copy()\n",
    "df_test_encoded['locale'] = df_test_encoded['locale'].map(loc2id)\n",
    "df_test_encoded['last_item'] = df_test_encoded['last_item'].map(product2id)\n",
    "df_test_encoded['prev_items'] = df_test_encoded['prev_items'].apply(lambda x: [product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B099NQFMG7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B00R9RZ9ZS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]</td>\n",
       "      <td>DE</td>\n",
       "      <td>B07G7Q5N6G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B08KQBYV43, 3955350843, 3955350843, 395535086...</td>\n",
       "      <td>DE</td>\n",
       "      <td>3955350843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09J945WQR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items locale   last_item\n",
       "0  [B08V12CT4C, B08V1KXBQD, B01BVG1XJS, B09VC5PKN...     DE  B099NQFMG7\n",
       "1               [B00R9R5ND6, B00R9RZ9ZS, B00R9RZ9ZS]     DE  B00R9RZ9ZS\n",
       "2   [B07YSRXJD3, B07G7Q5N6G, B08C9Q7QVK, B07G7Q5N6G]     DE  B07G7Q5N6G\n",
       "3  [B08KQBYV43, 3955350843, 3955350843, 395535086...     DE  3955350843\n",
       "4  [B09FPTCWMC, B09FPTQP68, B08HMRY8NG, B08TBBQ4B...     DE  B09J945WQR"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B09W9FND7K, B09JSPLN1M]</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09JSPLN1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "      <td>B001B4TKA0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "      <td>B00AZYORS2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0B71CHT1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09FKD61R8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items   next_item locale  \\\n",
       "0                           [B09W9FND7K, B09JSPLN1M]  B09M7GY217     DE   \n",
       "1   [B076THCGSG, B007MO8IME, B08MF65MLV, B001B4TKA0]  B001B4THSA     DE   \n",
       "2  [B0B1LGXWDS, B00AZYORS2, B0B1LGXWDS, B00AZYORS...  B0767DTG2Q     DE   \n",
       "3  [B09XMTWDVT, B0B4MZZ8MB, B0B7HZ2GWX, B09XMTWDV...  B0B4R9NN4B     DE   \n",
       "4               [B09Y5CSL3T, B09Y5DPTXN, B09FKD61R8]  B0BGVBKWGZ     DE   \n",
       "\n",
       "    last_item  \n",
       "0  B09JSPLN1M  \n",
       "1  B001B4TKA0  \n",
       "2  B00AZYORS2  \n",
       "3  B0B71CHT1L  \n",
       "4  B09FKD61R8  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = df_train\n",
    "df_train_encoded['locale'] = df_train_encoded['locale'].map(loc2id)\n",
    "df_train_encoded['last_item'] = df_train_encoded['last_item'].map(product2id)\n",
    "df_train_encoded['next_item'] = df_train_encoded['next_item'].map(product2id)\n",
    "df_train_encoded['prev_items'] = df_train_encoded['prev_items'].apply(lambda x: [product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[265193, 83226]</td>\n",
       "      <td>387776</td>\n",
       "      <td>0</td>\n",
       "      <td>83226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[38788, 85634, 4132, 71046]</td>\n",
       "      <td>335301</td>\n",
       "      <td>0</td>\n",
       "      <td>71046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[191882, 516876, 191882, 516876, 191882, 19188...</td>\n",
       "      <td>90141</td>\n",
       "      <td>0</td>\n",
       "      <td>516876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[136959, 261145, 31496, 136959, 261145, 31496,...</td>\n",
       "      <td>214540</td>\n",
       "      <td>0</td>\n",
       "      <td>469511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[291068, 410614, 4219]</td>\n",
       "      <td>338089</td>\n",
       "      <td>0</td>\n",
       "      <td>4219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0                                    [265193, 83226]     387776       0   \n",
       "1                        [38788, 85634, 4132, 71046]     335301       0   \n",
       "2  [191882, 516876, 191882, 516876, 191882, 19188...      90141       0   \n",
       "3  [136959, 261145, 31496, 136959, 261145, 31496,...     214540       0   \n",
       "4                             [291068, 410614, 4219]     338089       0   \n",
       "\n",
       "   last_item  \n",
       "0      83226  \n",
       "1      71046  \n",
       "2     516876  \n",
       "3     469511  \n",
       "4       4219  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410675"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_count = products.shape[0]\n",
    "id_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_encoded = products[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_encoded['id'] = products_encoded['id'].map(product2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  locale      price  len_title  len_desc  encode_brand  encode_color  \\\n",
       "0   0       0  30.950001       96.0     121.0        112134        203260   \n",
       "1   1       0  17.900000      186.0     330.0        124505        203260   \n",
       "2   2       0  68.889999      181.0      95.0        122979        114264   \n",
       "3   3       0  18.990000      101.0     191.0          9834         46931   \n",
       "4   4       0   7.170000       45.0      15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_encoded.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(df_sess_loc, df_test_loc):\n",
    "    res = []\n",
    "    for _, row in tqdm(df_sess_loc.iterrows(), total=len(df_sess_loc)):\n",
    "        prev_items = row['prev_items']\n",
    "        next_item = row['next_item']\n",
    "        prev_items.append(next_item)\n",
    "        res.append(prev_items)\n",
    "    \n",
    "    for _, row in tqdm(df_test_loc.iterrows(), total=len(df_test_loc)):\n",
    "        prev_items = row['prev_items']\n",
    "        res.append(prev_items)\n",
    "    \n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3606249/3606249 [03:39<00:00, 16439.99it/s]\n",
      "100%|██████████| 316971/316971 [00:17<00:00, 17684.62it/s]\n"
     ]
    }
   ],
   "source": [
    "id_seqs = get_seq(df_train_encoded, df_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/id_seqs.npy', id_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_window = 3\n",
    "w2v_min_count = 1\n",
    "w2v_epochs = 500\n",
    "w2v_vector_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec = Word2Vec(sentences=id_seqs, window=w2v_window, min_count=w2v_min_count, workers=40, epochs=w2v_epochs, vector_size=w2v_vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec.wv.save_word2vec_format('./data/word2vec_{}_{}_{}_{}.txt'.format(w2v_vector_size, w2v_epochs, w2v_window, w2v_min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec.save('./data/word2vec_{}_{}_{}_{}.pt'.format(w2v_vector_size, w2v_epochs, w2v_window, w2v_min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word2vec = Word2Vec.load('./data/word2vec_{}_{}_{}_{}.pt'.format(w2v_vector_size, w2v_epochs, w2v_window, w2v_min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [00:03<00:00, 358352.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405867\n",
      "1405878\n",
      "1405945\n",
      "1405974\n",
      "1406057\n",
      "1406093\n",
      "1406100\n",
      "1406105\n",
      "1406131\n",
      "1406163\n",
      "1406216\n",
      "1406225\n",
      "1406264\n",
      "1406326\n",
      "1406338\n",
      "1406353\n",
      "1406367\n",
      "1406398\n",
      "1406417\n",
      "1406418\n",
      "1406442\n",
      "1406462\n",
      "1406477\n",
      "1406498\n",
      "1406522\n",
      "1406527\n",
      "1406545\n",
      "1406571\n",
      "1406617\n",
      "1406634\n",
      "1406650\n",
      "1406666\n",
      "1406667\n",
      "1406688\n",
      "1406713\n",
      "1406729\n",
      "1406735\n",
      "1406736\n",
      "1406780\n",
      "1406834\n",
      "1406882\n",
      "1406925\n",
      "1406931\n",
      "1406932\n",
      "1406939\n",
      "1406941\n",
      "1406979\n",
      "1406989\n",
      "1407032\n",
      "1407058\n",
      "1407099\n",
      "1407108\n",
      "1407130\n",
      "1407131\n",
      "1407141\n",
      "1407143\n",
      "1407168\n",
      "1407179\n",
      "1407220\n",
      "1407225\n",
      "1407230\n",
      "1407237\n",
      "1407246\n",
      "1407261\n",
      "1407267\n",
      "1407280\n",
      "1407312\n",
      "1407322\n",
      "1407337\n",
      "1407353\n",
      "1407438\n",
      "1407463\n",
      "1407472\n",
      "1407479\n",
      "1407491\n",
      "1407502\n",
      "1407557\n",
      "1407582\n",
      "1407606\n",
      "1407630\n",
      "1407642\n",
      "1407674\n",
      "1407713\n",
      "1407740\n",
      "1407757\n",
      "1407855\n",
      "1407864\n",
      "1407881\n",
      "1407885\n",
      "1407887\n",
      "1407907\n",
      "1407918\n",
      "1407929\n",
      "1407970\n",
      "1407972\n",
      "1407980\n",
      "1408010\n",
      "1408020\n",
      "1408050\n",
      "1408051\n",
      "1408065\n",
      "1408090\n",
      "1408125\n",
      "1408130\n",
      "1408132\n",
      "1408149\n",
      "1408184\n",
      "1408198\n",
      "1408199\n",
      "1408206\n",
      "1408236\n",
      "1408259\n",
      "1408289\n",
      "1408404\n",
      "1408434\n",
      "1408443\n",
      "1408496\n",
      "1408529\n",
      "1408538\n",
      "1408550\n",
      "1408641\n",
      "1408643\n",
      "1408699\n",
      "1408729\n",
      "1408747\n",
      "1408754\n",
      "1408757\n",
      "1408770\n",
      "1408790\n",
      "1408812\n",
      "1408819\n",
      "1408841\n",
      "1408851\n",
      "1408882\n",
      "1408892\n",
      "1408909\n",
      "1408956\n",
      "1409000\n",
      "1409008\n",
      "1409145\n",
      "1409151\n",
      "1409228\n",
      "1409251\n",
      "1409254\n",
      "1409286\n",
      "1409345\n",
      "1409368\n",
      "1409424\n",
      "1409445\n",
      "1409471\n",
      "1409585\n",
      "1409587\n",
      "1409603\n",
      "1409632\n",
      "1409640\n",
      "1409682\n",
      "1409716\n",
      "1409732\n",
      "1409738\n",
      "1409775\n",
      "1409808\n",
      "1409837\n",
      "1409841\n",
      "1409877\n",
      "1409901\n",
      "1409906\n",
      "1409914\n",
      "1409929\n",
      "1409930\n",
      "1409964\n",
      "1409966\n",
      "1410007\n",
      "1410018\n",
      "1410023\n",
      "1410025\n",
      "1410090\n",
      "1410096\n",
      "1410115\n",
      "1410126\n",
      "1410132\n",
      "1410217\n",
      "1410334\n",
      "1410399\n",
      "1410407\n",
      "1410410\n",
      "1410448\n",
      "1410471\n",
      "1410533\n",
      "1410600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec_embedding = []\n",
    "for word in tqdm(range(id_count)):\n",
    "    try:\n",
    "        word2vec_embedding.append(id_word2vec.wv[word])\n",
    "    except:\n",
    "        # 部分word没有出现在id_seqs里边，就是不存在历史的那些id\n",
    "        print(word)\n",
    "        word2vec_embedding.append(np.zeros(w2v_vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/word2vec_embedding.npy', word2vec_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410675, 128)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_embedding = np.load('./data/word2vec_embedding.npy')\n",
    "word2vec_embedding.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[265193, 83226]</td>\n",
       "      <td>387776</td>\n",
       "      <td>0</td>\n",
       "      <td>83226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[38788, 85634, 4132, 71046]</td>\n",
       "      <td>335301</td>\n",
       "      <td>0</td>\n",
       "      <td>71046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[191882, 516876, 191882, 516876, 191882, 19188...</td>\n",
       "      <td>90141</td>\n",
       "      <td>0</td>\n",
       "      <td>516876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[136959, 261145, 31496, 136959, 261145, 31496,...</td>\n",
       "      <td>214540</td>\n",
       "      <td>0</td>\n",
       "      <td>469511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[291068, 410614, 4219]</td>\n",
       "      <td>338089</td>\n",
       "      <td>0</td>\n",
       "      <td>4219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0                                    [265193, 83226]     387776       0   \n",
       "1                        [38788, 85634, 4132, 71046]     335301       0   \n",
       "2  [191882, 516876, 191882, 516876, 191882, 19188...      90141       0   \n",
       "3  [136959, 261145, 31496, 136959, 261145, 31496,...     214540       0   \n",
       "4                             [291068, 410614, 4219]     338089       0   \n",
       "\n",
       "   last_item  \n",
       "0      83226  \n",
       "1      71046  \n",
       "2     516876  \n",
       "3     469511  \n",
       "4       4219  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[370409, 234018, 236816, 3188, 42450, 20661, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>26063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[136109, 425018, 425018]</td>\n",
       "      <td>0</td>\n",
       "      <td>425018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[36017, 46492, 511894, 46492]</td>\n",
       "      <td>0</td>\n",
       "      <td>46492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52581, 387953, 387953, 507424, 224806, 52581,...</td>\n",
       "      <td>0</td>\n",
       "      <td>387953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[371901, 388062, 401264, 449222, 248094, 43829...</td>\n",
       "      <td>0</td>\n",
       "      <td>96347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  locale  last_item\n",
       "0  [370409, 234018, 236816, 3188, 42450, 20661, 2...       0      26063\n",
       "1                           [136109, 425018, 425018]       0     425018\n",
       "2                      [36017, 46492, 511894, 46492]       0      46492\n",
       "3  [52581, 387953, 387953, 507424, 224806, 52581,...       0     387953\n",
       "4  [371901, 388062, 401264, 449222, 248094, 43829...       0      96347"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  locale      price  len_title  len_desc  encode_brand  encode_color  \\\n",
       "0   0       0  30.950001       96.0     121.0        112134        203260   \n",
       "1   1       0  17.900000      186.0     330.0        124505        203260   \n",
       "2   2       0  68.889999      181.0      95.0        122979        114264   \n",
       "3   3       0  18.990000      101.0     191.0          9834         46931   \n",
       "4   4       0   7.170000       45.0      15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3606249, 5), (316971, 3))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.shape, df_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 训练集的部分样本召回的时候，没有找到真实的label。这些对于训练来说就没有用了！修改一下，看看要不要直接把label加进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 召回的结果\n",
    "train_preds = pickle.load(open('./data/train_preds_all.pkl', 'rb'))\n",
    "test_preds = pickle.load(open('./data/test_preds_all.pkl', 'rb'))\n",
    "len(train_preds), len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_encoded = []\n",
    "for x in train_preds:\n",
    "    train_preds_encoded.append([product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_encoded = []\n",
    "for x in test_preds:\n",
    "    test_preds_encoded.append([product2id[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3606249, 316971)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_preds_encoded), len(test_preds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_preds_encoded, open('./data/train_preds_all_encoded.pkl', 'wb'))\n",
    "pickle.dump(test_preds_encoded, open('./data/test_preds_all_encoded.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_encoded = pickle.load(open('./data/train_preds_all_encoded.pkl', 'rb'))\n",
    "test_preds_encoded = pickle.load(open('./data/test_preds_all_encoded.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded['recall'] = train_preds_encoded\n",
    "df_test_encoded['recall'] = test_preds_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[265193, 83226]</td>\n",
       "      <td>387776</td>\n",
       "      <td>0</td>\n",
       "      <td>83226</td>\n",
       "      <td>[265193, 387776, 174133, 54056, 236419, 374995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[38788, 85634, 4132, 71046]</td>\n",
       "      <td>335301</td>\n",
       "      <td>0</td>\n",
       "      <td>71046</td>\n",
       "      <td>[335301, 484264, 153628, 725260, 654971, 69944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[191882, 516876, 191882, 516876, 191882, 19188...</td>\n",
       "      <td>90141</td>\n",
       "      <td>0</td>\n",
       "      <td>516876</td>\n",
       "      <td>[191882, 90141, 111147, 123364, 405548, 320543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[136959, 261145, 31496, 136959, 261145, 31496,...</td>\n",
       "      <td>214540</td>\n",
       "      <td>0</td>\n",
       "      <td>469511</td>\n",
       "      <td>[375995, 219917, 136959, 285874, 506621, 26114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[291068, 410614, 4219]</td>\n",
       "      <td>338089</td>\n",
       "      <td>0</td>\n",
       "      <td>4219</td>\n",
       "      <td>[338089, 435967, 210849, 221386, 153628, 72526...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0                                    [265193, 83226]     387776       0   \n",
       "1                        [38788, 85634, 4132, 71046]     335301       0   \n",
       "2  [191882, 516876, 191882, 516876, 191882, 19188...      90141       0   \n",
       "3  [136959, 261145, 31496, 136959, 261145, 31496,...     214540       0   \n",
       "4                             [291068, 410614, 4219]     338089       0   \n",
       "\n",
       "   last_item                                             recall  \n",
       "0      83226  [265193, 387776, 174133, 54056, 236419, 374995...  \n",
       "1      71046  [335301, 484264, 153628, 725260, 654971, 69944...  \n",
       "2     516876  [191882, 90141, 111147, 123364, 405548, 320543...  \n",
       "3     469511  [375995, 219917, 136959, 285874, 506621, 26114...  \n",
       "4       4219  [338089, 435967, 210849, 221386, 153628, 72526...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[370409, 234018, 236816, 3188, 42450, 20661, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>26063</td>\n",
       "      <td>[65806, 160459, 236816, 311332, 437685, 329918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[136109, 425018, 425018]</td>\n",
       "      <td>0</td>\n",
       "      <td>425018</td>\n",
       "      <td>[12377, 136109, 510746, 335229, 100932, 357096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[36017, 46492, 511894, 46492]</td>\n",
       "      <td>0</td>\n",
       "      <td>46492</td>\n",
       "      <td>[511894, 46492, 36017, 204024, 199383, 409670,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52581, 387953, 387953, 507424, 224806, 52581,...</td>\n",
       "      <td>0</td>\n",
       "      <td>387953</td>\n",
       "      <td>[507424, 387953, 177699, 316651, 224806, 52581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[371901, 388062, 401264, 449222, 248094, 43829...</td>\n",
       "      <td>0</td>\n",
       "      <td>96347</td>\n",
       "      <td>[43829, 248094, 446203, 158521, 162660, 399730...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  locale  last_item  \\\n",
       "0  [370409, 234018, 236816, 3188, 42450, 20661, 2...       0      26063   \n",
       "1                           [136109, 425018, 425018]       0     425018   \n",
       "2                      [36017, 46492, 511894, 46492]       0      46492   \n",
       "3  [52581, 387953, 387953, 507424, 224806, 52581,...       0     387953   \n",
       "4  [371901, 388062, 401264, 449222, 248094, 43829...       0      96347   \n",
       "\n",
       "                                              recall  \n",
       "0  [65806, 160459, 236816, 311332, 437685, 329918...  \n",
       "1  [12377, 136109, 510746, 335229, 100932, 357096...  \n",
       "2  [511894, 46492, 36017, 204024, 199383, 409670,...  \n",
       "3  [507424, 387953, 177699, 316651, 224806, 52581...  \n",
       "4  [43829, 248094, 446203, 158521, 162660, 399730...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_encoded['next_item'] = [id_count] * len(df_test_encoded)\n",
    "df_test_encoded.insert(1, 'next_item', [id_count] * len(df_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "      <th>last_item</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[370409, 234018, 236816, 3188, 42450, 20661, 2...</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>26063</td>\n",
       "      <td>[65806, 160459, 236816, 311332, 437685, 329918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[136109, 425018, 425018]</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>425018</td>\n",
       "      <td>[12377, 136109, 510746, 335229, 100932, 357096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[36017, 46492, 511894, 46492]</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>46492</td>\n",
       "      <td>[511894, 46492, 36017, 204024, 199383, 409670,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52581, 387953, 387953, 507424, 224806, 52581,...</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>387953</td>\n",
       "      <td>[507424, 387953, 177699, 316651, 224806, 52581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[371901, 388062, 401264, 449222, 248094, 43829...</td>\n",
       "      <td>1410675</td>\n",
       "      <td>0</td>\n",
       "      <td>96347</td>\n",
       "      <td>[43829, 248094, 446203, 158521, 162660, 399730...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prev_items  next_item  locale  \\\n",
       "0  [370409, 234018, 236816, 3188, 42450, 20661, 2...    1410675       0   \n",
       "1                           [136109, 425018, 425018]    1410675       0   \n",
       "2                      [36017, 46492, 511894, 46492]    1410675       0   \n",
       "3  [52581, 387953, 387953, 507424, 224806, 52581,...    1410675       0   \n",
       "4  [371901, 388062, 401264, 449222, 248094, 43829...    1410675       0   \n",
       "\n",
       "   last_item                                             recall  \n",
       "0      26063  [65806, 160459, 236816, 311332, 437685, 329918...  \n",
       "1     425018  [12377, 136109, 510746, 335229, 100932, 357096...  \n",
       "2      46492  [511894, 46492, 36017, 204024, 199383, 409670,...  \n",
       "3     387953  [507424, 387953, 177699, 316651, 224806, 52581...  \n",
       "4      96347  [43829, 248094, 446203, 158521, 162660, 399730...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>price</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_desc</th>\n",
       "      <th>encode_brand</th>\n",
       "      <th>encode_color</th>\n",
       "      <th>encode_size</th>\n",
       "      <th>encode_model</th>\n",
       "      <th>encode_material</th>\n",
       "      <th>encode_author</th>\n",
       "      <th>encode_price</th>\n",
       "      <th>encode_len_title</th>\n",
       "      <th>encode_len_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112134</td>\n",
       "      <td>203260</td>\n",
       "      <td>218060</td>\n",
       "      <td>426630</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>186.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>124505</td>\n",
       "      <td>203260</td>\n",
       "      <td>128007</td>\n",
       "      <td>524101</td>\n",
       "      <td>45568</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68.889999</td>\n",
       "      <td>181.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>122979</td>\n",
       "      <td>114264</td>\n",
       "      <td>170270</td>\n",
       "      <td>145013</td>\n",
       "      <td>15566</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>101.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>9834</td>\n",
       "      <td>46931</td>\n",
       "      <td>218060</td>\n",
       "      <td>67408</td>\n",
       "      <td>29357</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105135</td>\n",
       "      <td>117844</td>\n",
       "      <td>170305</td>\n",
       "      <td>174527</td>\n",
       "      <td>23064</td>\n",
       "      <td>30835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  locale      price  len_title  len_desc  encode_brand  encode_color  \\\n",
       "0   0       0  30.950001       96.0     121.0        112134        203260   \n",
       "1   1       0  17.900000      186.0     330.0        124505        203260   \n",
       "2   2       0  68.889999      181.0      95.0        122979        114264   \n",
       "3   3       0  18.990000      101.0     191.0          9834         46931   \n",
       "4   4       0   7.170000       45.0      15.0        105135        117844   \n",
       "\n",
       "   encode_size  encode_model  encode_material  encode_author  encode_price  \\\n",
       "0       218060        426630            45568          30835             0   \n",
       "1       128007        524101            45568          30835             0   \n",
       "2       170270        145013            15566          30835             0   \n",
       "3       218060         67408            29357          30835             0   \n",
       "4       170305        174527            23064          30835             0   \n",
       "\n",
       "   encode_len_title  encode_len_desc  \n",
       "0                 2                2  \n",
       "1                 4                5  \n",
       "2                 4                1  \n",
       "3                 2                3  \n",
       "4                 0                0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded[['prev_items', 'next_item', 'locale', 'last_item']].to_csv('data/df_train_encoded.csv', index=False)\n",
    "df_test_encoded[['prev_items', 'next_item', 'locale', 'last_item']].to_csv('data/df_test_encoded.csv', index=False)\n",
    "products_encoded.to_csv('./data/products_encoded.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1410675, 384) (1410675, 384)\n",
      "1410675 1410675\n",
      "(1410675, 128)\n",
      "(3606249, 4) (316971, 4) (1410675, 14)\n",
      "3606249 316971\n"
     ]
    }
   ],
   "source": [
    "loc2id = {\n",
    "    'DE': 0,\n",
    "    'JP': 1,\n",
    "    'UK': 2,\n",
    "    'ES': 3,\n",
    "    'FR': 4,\n",
    "    'IT': 5\n",
    "}\n",
    "\n",
    "titles_embedding = np.load('./data/titles_embedding.npy')\n",
    "descs_embedding = np.load('./data/descs_embedding.npy')\n",
    "print(titles_embedding.shape, descs_embedding.shape)\n",
    "\n",
    "product2id = json.load(open('data/product2id.json', 'r'))\n",
    "id2product = json.load(open('data/id2product.json', 'r'))\n",
    "id2product = {int(k): v for k, v in id2product.items()}\n",
    "print(len(product2id), len(id2product))\n",
    "\n",
    "word2vec_embedding = np.load('./data/word2vec_embedding.npy')\n",
    "print(word2vec_embedding.shape)\n",
    "\n",
    "df_train_encoded = pd.read_csv('data/df_train_encoded.csv')\n",
    "df_test_encoded = pd.read_csv('data/df_test_encoded.csv')\n",
    "products_encoded = pd.read_csv('./data/products_encoded.csv')\n",
    "print(df_train_encoded.shape, df_test_encoded.shape, products_encoded.shape)\n",
    "\n",
    "id_count = products_encoded.shape[0]\n",
    "\n",
    "train_preds_encoded = pickle.load(open('./data/train_preds_all_encoded.pkl', 'rb'))\n",
    "test_preds_encoded = pickle.load(open('./data/test_preds_all_encoded.pkl', 'rb'))\n",
    "print(len(train_preds_encoded), len(test_preds_encoded))\n",
    "\n",
    "df_train_encoded['recall'] = train_preds_encoded\n",
    "df_test_encoded['recall'] = test_preds_encoded\n",
    "\n",
    "df_train_encoded['prev_items'] = df_train_encoded['prev_items'].apply(eval)\n",
    "df_test_encoded['prev_items'] = df_test_encoded['prev_items'].apply(eval)\n",
    "\n",
    "num_features = ['price', 'len_title', 'len_desc']\n",
    "for fe in num_features:\n",
    "    products_encoded[fe] = products_encoded[fe].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNDataset(Dataset):\n",
    "    def __init__(self, df, product2id):\n",
    "        super(NNDataset, self).__init__()\n",
    "        self.df = df.copy()\n",
    "        self.product2id = product2id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ['prev_items', 'next_item', 'locale', 'last_item', 'recall']\n",
    "        sample = self.df.iloc[idx].values\n",
    "        return sample[0], sample[2], sample[4], sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 16\n",
    "dense_bins = 10\n",
    "hid_dim = 256\n",
    "dropout = 0.5\n",
    "layers = 4\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "lr_patience = 5\n",
    "lr_decay_ratio = 0.1\n",
    "batch_size = 256\n",
    "epochs = 20\n",
    "lr = 1e-3\n",
    "log_every = 100\n",
    "early_stop = True\n",
    "patience = 10\n",
    "kfold = 5\n",
    "device = torch.device('cuda:2')\n",
    "\n",
    "w2v_window = 3\n",
    "w2v_min_count = 1\n",
    "w2v_epochs = 500\n",
    "w2v_vector_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = NNDataset(df_train_encoded, product2id)\n",
    "test_set = NNDataset(df_test_encoded, product2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(indices):\n",
    "    batch_prev_items = []\n",
    "    batch_locale = []\n",
    "    batch_candidate_set = []\n",
    "    batch_len = []\n",
    "    batch_mask = []\n",
    "    batch_label = []\n",
    "    batch_label_index = []  # 交叉熵需要的是label在候选集中的index\n",
    "    for item in indices:\n",
    "        batch_len.append(len(item[0]))  # prev_items\n",
    "    max_len = max(batch_len)\n",
    "    for item in indices:\n",
    "        l = len(item[0])\n",
    "        batch_mask.append([1] * (l) + [0] * (max_len - l))  # 0代表padding的位置，需要mask\n",
    "    for item in indices:\n",
    "        # ['prev_items', 'locale', 'recall', 'next_item']\n",
    "        prev_items = item[0].copy()\n",
    "        while (len(prev_items) < max_len):\n",
    "            prev_items.append(id_count)  # embdding的时候id_count+1，把id_count作为padding了\n",
    "        batch_prev_items.append(prev_items)\n",
    "        batch_locale.append(item[1])\n",
    "        batch_candidate_set.append(item[2].copy())\n",
    "        batch_label.append(item[3])\n",
    "        if item[3] in item[2]:\n",
    "            batch_label_index.append(item[2].index(item[3]))\n",
    "        else:\n",
    "            batch_label_index.append(len(item[2]))\n",
    "    return [torch.LongTensor(batch_prev_items).to(device), torch.LongTensor(batch_locale).to(device), \n",
    "            torch.LongTensor(batch_candidate_set).to(device),\n",
    "            torch.LongTensor(batch_len).to(device), torch.LongTensor(batch_mask).to(device), \n",
    "            torch.LongTensor(batch_label).to(device), torch.LongTensor(batch_label_index).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14087/14087 [22:23<00:00, 10.48it/s]  \n"
     ]
    }
   ],
   "source": [
    "label_index = []\n",
    "for i, (batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "    # print(batch_prev_items.shape, batch_locale.shape, batch_candidate_set.shape, batch_len.shape, batch_mask.shape, batch_label.shape, batch_label_index.shape)\n",
    "    label_index.append(batch_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3606249])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat(label_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = torch.concat(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = label_index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/label_index_train.npy', label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = pd.DataFrame(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      855497\n",
       "1      507747\n",
       "2      339815\n",
       "100    300894\n",
       "3      240393\n",
       "        ...  \n",
       "94        726\n",
       "96        704\n",
       "97        658\n",
       "98        636\n",
       "99        628\n",
       "Length: 101, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_index.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.724018\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(label_index < 10).sum() / len(df_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_idx_list = np.load('data/5fold_trn_idx_list.npy', allow_pickle=True)\n",
    "val_idx_list = np.load('data/5fold_val_idx_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_index.iloc[trn_idx_list[Fold]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "label_index.iloc[val_idx_list[Fold]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for i, (batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "#     # print(batch_prev_items.shape, batch_locale.shape, batch_candidate_set.shape, batch_len.shape, batch_mask.shape, batch_label.shape, batch_label_index.shape)\n",
    "#     cnt += (batch_label_index == 100).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt / len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index) in enumerate(test_loader):\n",
    "#     print(batch_prev_items.shape, batch_locale.shape, batch_candidate_set.shape, batch_len.shape, batch_mask.shape, batch_label.shape, batch_label_index.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader), len(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.locale_emb = nn.Embedding(len(loc2id), self.emb_dim)\n",
    "        \n",
    "        self.price_emb = nn.Linear(1, self.emb_dim)\n",
    "        self.len_title_emb = nn.Linear(1, self.emb_dim)\n",
    "        self.len_desc_emb = nn.Linear(1, self.emb_dim)\n",
    "        \n",
    "        self.encode_brand_emb = nn.Embedding(products_encoded['encode_brand'].nunique(), self.emb_dim)\n",
    "        self.encode_color_emb = nn.Embedding(products_encoded['encode_color'].nunique(), self.emb_dim)\n",
    "        self.encode_size_emb = nn.Embedding(products_encoded['encode_size'].nunique(), self.emb_dim)\n",
    "        self.encode_model_emb = nn.Embedding(products_encoded['encode_model'].nunique(), self.emb_dim)\n",
    "        self.encode_material_emb = nn.Embedding(products_encoded['encode_material'].nunique(), self.emb_dim)\n",
    "        self.encode_author_emb = nn.Embedding(products_encoded['encode_author'].nunique(), self.emb_dim)\n",
    "\n",
    "        self.encode_price_emb = nn.Embedding(dense_bins, self.emb_dim)\n",
    "        self.encode_len_title_emb = nn.Embedding(dense_bins, self.emb_dim)\n",
    "        self.encode_len_desc_emb = nn.Embedding(dense_bins, self.emb_dim)\n",
    "\n",
    "    def load_init():\n",
    "        pass\n",
    "\n",
    "    def forward(self, batch_products):\n",
    "        \"\"\"\n",
    "            batch_products: dict \n",
    "        \"\"\"\n",
    "        locale_emb = self.locale_emb(batch_products['locale'])\n",
    "        \n",
    "        price_emb = self.price_emb(batch_products['price'].unsqueeze(-1))\n",
    "        len_title_emb = self.len_title_emb(batch_products['len_title'].unsqueeze(-1))\n",
    "        len_desc_emb = self.len_desc_emb(batch_products['len_desc'].unsqueeze(-1))\n",
    "        \n",
    "        encode_brand_emb = self.encode_brand_emb(batch_products['encode_brand'])\n",
    "        encode_color_emb = self.encode_color_emb(batch_products['encode_color'])\n",
    "        encode_size_emb = self.encode_size_emb(batch_products['encode_size'])\n",
    "        encode_model_emb = self.encode_model_emb(batch_products['encode_model'])\n",
    "        encode_material_emb = self.encode_material_emb(batch_products['encode_material'])\n",
    "        encode_author_emb = self.encode_author_emb(batch_products['encode_author'])\n",
    "\n",
    "        encode_price_emb = self.encode_price_emb(batch_products['encode_price'])\n",
    "        encode_len_title_emb = self.encode_len_title_emb(batch_products['encode_len_title'])\n",
    "        encode_len_desc_emb = self.encode_len_desc_emb(batch_products['encode_len_desc'])\n",
    "\n",
    "        # 将所有特征的表征按照一定的方式组合起来得到这个产品的向量表示\n",
    "        products_vec = torch.cat([locale_emb, \n",
    "                                  price_emb, len_title_emb, len_desc_emb,\n",
    "                                  encode_brand_emb, encode_color_emb, encode_size_emb, \n",
    "                                  encode_model_emb, encode_material_emb, encode_author_emb, \n",
    "                                  encode_price_emb, encode_len_title_emb, encode_len_desc_emb], dim=1)\n",
    "        return products_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, products_input):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.product_fea = Product().to(device)\n",
    "        product_fea_emb = self.product_fea(products_input)  # (id_count, 208)\n",
    "        self.padding_emb = torch.zeros((1, product_fea_emb.shape[1]), requires_grad=False).to(device)\n",
    "        self.product_fea_emb = torch.cat([product_fea_emb, self.padding_emb], dim=0)  # (id_count + 1, 208)\n",
    "        self.title_emb = nn.Embedding(id_count + 1, embedding_dim=384, padding_idx=id_count)\n",
    "        self.title_linear = nn.Linear(384, self.emb_dim * 2)\n",
    "        self.desc_emb = nn.Embedding(id_count + 1, embedding_dim=384, padding_idx=id_count)\n",
    "        self.desc_linear = nn.Linear(384, self.emb_dim * 2)\n",
    "        self.w2v_emb = nn.Embedding(id_count + 1, embedding_dim=w2v_vector_size, padding_idx=id_count)\n",
    "        self.w2v_linear = nn.Linear(w2v_vector_size, self.emb_dim * 2)\n",
    "        self.title_emb.weight.data[:self.id_count].copy_(torch.tensor(titles_embedding))\n",
    "        self.desc_emb.weight.data[:self.id_count].copy_(torch.tensor(descs_embedding))\n",
    "        self.w2v_emb.weight.data[:self.id_count].copy_(torch.tensor(word2vec_embedding))\n",
    "        self.title_emb.weight.requires_grad = False\n",
    "        self.desc_emb.weight.requires_grad = False\n",
    "        self.w2v_emb.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, batch_prev_items, batch_candidate_set=None):\n",
    "        \"\"\"\n",
    "            batch_prev_items: (B, len)\n",
    "            batch_candidate_set: (B, 100)\n",
    "        \"\"\"\n",
    "        # print(batch_prev_items.shape, batch_candidate_set.shape, batch_label.shape)\n",
    "        # print(self.product_fea_emb[batch_prev_items].shape)\n",
    "        # 对输入序列中的每个商品，获取它的嵌入表示并拼接\n",
    "        batch_prev_items_emb = torch.cat([\n",
    "            self.product_fea_emb[batch_prev_items],  # 商品特征嵌入\n",
    "            self.title_linear(self.title_emb(batch_prev_items)), \n",
    "            self.desc_linear(self.desc_emb(batch_prev_items)), \n",
    "            self.w2v_linear(self.w2v_emb(batch_prev_items))\n",
    "        ], dim=-1)\n",
    "        # 对候选集中的每个商品，获取它的嵌入表示并拼接\n",
    "        if batch_candidate_set is not None:\n",
    "            batch_candidate_set_emb = torch.cat([\n",
    "                self.product_fea_emb[batch_candidate_set],  # 商品特征嵌入\n",
    "                self.title_linear(self.title_emb(batch_candidate_set)), \n",
    "                self.desc_linear(self.desc_emb(batch_candidate_set)), \n",
    "                self.w2v_linear(self.w2v_emb(batch_candidate_set))\n",
    "            ], dim=-1)\n",
    "        else:\n",
    "            batch_candidate_set_emb = None\n",
    "        # # 对标签序列中的每个商品，获取它的嵌入表示并拼接\n",
    "        # batch_label_emb = torch.cat([\n",
    "        #     self.product_fea_emb[batch_label],  # 商品特征嵌入\n",
    "        #     self.title_linear(self.title_emb(batch_label)), \n",
    "        #     self.desc_linear(self.desc_emb(batch_label)), \n",
    "        #     self.w2v_linear(self.w2v_emb(batch_label))\n",
    "        # ], dim=-1)\n",
    "        # print(batch_prev_items_emb.shape, batch_candidate_set_emb.shape, batch_label_emb.shape)\n",
    "        return batch_prev_items_emb, batch_candidate_set_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntraAttention(nn.Module):\n",
    "    \"\"\"对轨迹经过 LSTM 后的隐藏层向量序列做 Attention 强化\n",
    "    key: 当前轨迹经过 LSTM 后的隐藏层向量序列\n",
    "    query: 轨迹向量序列的最后一个状态\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(IntraAttention, self).__init__()\n",
    "        # 模型参数\n",
    "        self.hidden_size = hidden_size\n",
    "        # 模型结构\n",
    "        self.w1 = nn.Linear(in_features=self.hidden_size, out_features=1, bias=False)\n",
    "        self.w2 = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size, bias=False)\n",
    "        self.w3 = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, query, key, mask=None):\n",
    "        \"\"\"前馈\n",
    "\n",
    "        Args:\n",
    "            query (tensor): shape (batch_size, hidden_size)\n",
    "            key (tensor): shape (batch_size, seq_len, hidden_size)\n",
    "            mask (tensor): padding mask, 1 表示非补齐值, 0 表示补齐值 shape (batch_size, seq_len)\n",
    "        Return:\n",
    "            attn_hidden (tensor): shape (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        attn_weight = torch.bmm(key, query.unsqueeze(2)).squeeze(2) # shape (batch_size, seq_len)\n",
    "        if mask is not None:\n",
    "            mask = attn_weight.masked_fill(mask==0, -1e9) # mask \n",
    "        attn_weight = torch.softmax(attn_weight, dim=1).unsqueeze(2) # shape (batch_size, seq_len, 1)\n",
    "        attn_hidden = torch.sum(attn_weight * key, dim=1)\n",
    "        return attn_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, products_input):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hid_dim\n",
    "        self.layers = layers\n",
    "        self.dropout = dropout\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.input_size = (products_encoded.shape[1] - 1) * self.emb_dim + 1 * 2 * self.emb_dim\n",
    "\n",
    "        self.product_emb = ProductEmbedding(products_input).to(device)\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.layers, batch_first=True)\n",
    "        self.intra_attn = IntraAttention(hidden_size=self.hidden_size)\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.output = nn.Linear(in_features=self.hidden_size, out_features=id_count)  # 所有的id的个数\n",
    "\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=100)  # 候选集大小100\n",
    "\n",
    "    def forward(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_prev_items: (B, len)\n",
    "            batch_locale: (B,)\n",
    "            batch_candidate_set: (B, 100)\n",
    "            batch_len: (B,)\n",
    "            batch_label: (B,)\n",
    "            batch_mask: (B, len)\n",
    "        \n",
    "        Return:\n",
    "            candidate_prob (tensor): 对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        batch_prev_items_emb, batch_candidate_set_emb = self.product_emb(batch_prev_items, None)\n",
    "        # batch_prev_items_emb (B, len, input_size)\n",
    "        # batch_candidate_set_emb (B, 100, input_size) or None\n",
    "\n",
    "        input_emb = self.dropout(batch_prev_items_emb)\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        if batch_mask is not None:\n",
    "            # LSTM with Mask\n",
    "            pack_input = pack_padded_sequence(input_emb, lengths=batch_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            pack_lstm_hidden, (hn, cn) = self.lstm(pack_input)\n",
    "            lstm_hidden, _ = pad_packed_sequence(pack_lstm_hidden, batch_first=True) # (B, len, hidden_size)\n",
    "        else:\n",
    "            lstm_hidden, (hn, cn) = self.lstm(input_emb) # (B, len, hidden_size)\n",
    "        \n",
    "        if batch_mask is not None:\n",
    "            # 获取序列最后一个非补齐值对应的 hidden\n",
    "            lstm_last_index = batch_len - 1 # (batch_size)\n",
    "            lstm_last_index = lstm_last_index.reshape(lstm_last_index.shape[0], 1, -1) # (B, 1, 1)\n",
    "            lstm_last_index = lstm_last_index.repeat(1, 1, self.hidden_size) # (B, 1, hidden_size)\n",
    "            lstm_last_hidden = torch.gather(lstm_hidden, dim=1, index=lstm_last_index).squeeze(1) # (B, hidden_size)\n",
    "        else:\n",
    "            lstm_last_hidden = lstm_hidden[:, -1, :] # (B, hidden_size)\n",
    "        attn_hidden = self.intra_attn(query=lstm_last_hidden, key=lstm_hidden, mask=batch_mask) # (B, hidden_size)\n",
    "        attn_hidden = self.dropout(attn_hidden) # (B, hidden_size)\n",
    "        \n",
    "        # 使用线性层直接预测\n",
    "        score = self.output(attn_hidden)  # (batch_size, id_count)\n",
    "        \n",
    "        # 根据 candidate_set 选出对应 candidate 的 score\n",
    "        candidate_score = torch.gather(score, dim=1, index=batch_candidate_set)  # (batch_size, candidate_count)\n",
    "        return candidate_score\n",
    "\n",
    "    def predict(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"预测\n",
    "        Return:\n",
    "            candidate_prob (tensor): softmax 后对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, False)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return torch.softmax(score, dim=1), loss\n",
    "\n",
    "    def calculate_loss(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            loss (tensor): 交叉损失熵 (1)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, True)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher(nn.Module):\n",
    "    \"\"\"Matcher 匹配打分\n",
    "    根据当前轨迹隐藏层表征与候选集表征之间计算一个匹配程度，也就是下一跳的评分\n",
    "\n",
    "    目前因为候选集表征与隐藏层表征维度不一样，所以对候选集表征过一个线性映射来计算。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, item_emb_size):\n",
    "        super(Matcher, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.item_emb_size = item_emb_size\n",
    "        self.linear = nn.Linear(in_features=self.item_emb_size, out_features=self.hidden_size)\n",
    "\n",
    "    def forward(self, items_hidden, candidate_emb):\n",
    "        \"\"\"前馈\n",
    "\n",
    "        Args:\n",
    "            items_hidden (tensor): 历史序列的隐藏层表征 (batch_size, hidden_size)\n",
    "            candidate_emb (tensor): 候选集表征 (batch_size, candidate_size, item_emb_size)\n",
    "        \"\"\"\n",
    "        candidate_hidden = self.linear(candidate_emb).permute(0, 2, 1) # (batch_size, hidden_size, candidate_size)\n",
    "        score = torch.bmm(items_hidden.unsqueeze(1), candidate_hidden).squeeze(1) # (batch_size, candidate_size)\n",
    "        return score\n",
    "\n",
    "\n",
    "class MatcherV2(nn.Module):\n",
    "    \"\"\"候选集与当前轨迹状态之间的注意力模块\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, item_emb_size, dropout):\n",
    "        super(MatcherV2, self).__init__()\n",
    "        self.out_linear = nn.Linear(in_features=hidden_size, out_features=1, bias=False)\n",
    "        self.w1_linear = nn.Linear(in_features=hidden_size, out_features=hidden_size, bias=False)\n",
    "        self.w2_linear = nn.Linear(in_features=item_emb_size, out_features=hidden_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        \"\"\"\n",
    "        计算 query 与 key 之间的相似度\n",
    "        计算方法为可学习前馈神经网络：attn_weight = w_out * tanh(w_1 * query + w_2 * key)\n",
    "        Args:\n",
    "            query: 历史序列的隐藏层表征 shape: (batch_size, hidden_size)\n",
    "            key: 候选集的嵌入向量 shape: (batch_size, candidate_size, item_emb_size)\n",
    "            hidden_size = item_emb_size\n",
    "\n",
    "        Returns:\n",
    "            candidate_weight: 当前状态与候选集之间的相关性向量。shape: (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        query_hidden = torch.relu(self.w1_linear(query).unsqueeze(1))  # shape: (batch_size, 1, hidden_size)\n",
    "        key_hidden = torch.relu(self.w2_linear(key))  # shape: (batch_size, candidate_size, hidden_size)\n",
    "        candidate_weight = torch.tanh(query_hidden + key_hidden)  # shape: (batch_size, candidate_size, hidden_size)\n",
    "        candidate_weight = self.dropout(candidate_weight)\n",
    "        out = self.out_linear(candidate_weight).squeeze(2)  # shape: (batch_size, candidate_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchModel(nn.Module):\n",
    "\n",
    "    def __init__(self, products_input):\n",
    "        super(MatchModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hid_dim\n",
    "        self.layers = layers\n",
    "        self.dropout_p = dropout\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.input_size = (products_encoded.shape[1] - 1) * self.emb_dim + 1 * 2 * self.emb_dim\n",
    "\n",
    "        self.product_emb = ProductEmbedding(products_input).to(device)\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.layers, batch_first=True)\n",
    "        self.intra_attn = IntraAttention(hidden_size=self.hidden_size)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_p)\n",
    "        if atten_match:\n",
    "            self.output = MatcherV2(hidden_size=self.hidden_size, item_emb_size=self.input_size, dropout=self.dropout_p)\n",
    "        else:\n",
    "            self.output = Matcher(hidden_size=self.hidden_size, item_emb_size=self.input_size)\n",
    "\n",
    "        self.loss_func = nn.CrossEntropyLoss(ignore_index=100)  # 候选集大小100\n",
    "\n",
    "    def forward(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_prev_items: (B, len)\n",
    "            batch_locale: (B,)\n",
    "            batch_candidate_set: (B, 100)\n",
    "            batch_len: (B,)\n",
    "            batch_label: (B,)\n",
    "            batch_mask: (B, len)\n",
    "        \n",
    "        Return:\n",
    "            candidate_prob (tensor): 对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        batch_prev_items_emb, batch_candidate_set_emb = self.product_emb(batch_prev_items, batch_candidate_set)\n",
    "        # batch_prev_items_emb (B, len, input_size)\n",
    "        # batch_candidate_set_emb (B, 100, input_size) or None\n",
    "\n",
    "        input_emb = self.dropout(batch_prev_items_emb)\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        if batch_mask is not None:\n",
    "            # LSTM with Mask\n",
    "            pack_input = pack_padded_sequence(input_emb, lengths=batch_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            pack_lstm_hidden, (hn, cn) = self.lstm(pack_input)\n",
    "            lstm_hidden, _ = pad_packed_sequence(pack_lstm_hidden, batch_first=True) # (B, len, hidden_size)\n",
    "        else:\n",
    "            lstm_hidden, (hn, cn) = self.lstm(input_emb) # (B, len, hidden_size)\n",
    "        \n",
    "        if batch_mask is not None:\n",
    "            # 获取序列最后一个非补齐值对应的 hidden\n",
    "            lstm_last_index = batch_len - 1 # (batch_size)\n",
    "            lstm_last_index = lstm_last_index.reshape(lstm_last_index.shape[0], 1, -1) # (B, 1, 1)\n",
    "            lstm_last_index = lstm_last_index.repeat(1, 1, self.hidden_size) # (B, 1, hidden_size)\n",
    "            lstm_last_hidden = torch.gather(lstm_hidden, dim=1, index=lstm_last_index).squeeze(1) # (B, hidden_size)\n",
    "        else:\n",
    "            lstm_last_hidden = lstm_hidden[:, -1, :] # (B, hidden_size)\n",
    "        attn_hidden = self.intra_attn(query=lstm_last_hidden, key=lstm_hidden, mask=batch_mask) # (B, hidden_size)\n",
    "        attn_hidden = self.dropout(attn_hidden) # (B, hidden_size)\n",
    "        \n",
    "        # Matcher\n",
    "        candidate_score = self.output(attn_hidden, batch_candidate_set_emb)  # (batch_size, candidate_size)\n",
    "        return candidate_score\n",
    "\n",
    "    def predict(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"预测\n",
    "        Return:\n",
    "            candidate_prob (tensor): softmax 后对候选集下一跳的概率预测 (batch_size, candidate_size)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, False)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return torch.softmax(score, dim=1), loss\n",
    "\n",
    "    def calculate_loss(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask=None):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            loss (tensor): 交叉损失熵 (1)\n",
    "        \"\"\"\n",
    "        score = self.forward(batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, True)\n",
    "        loss = self.loss_func(score, batch_label)\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 16\n",
    "dense_bins = 10\n",
    "hid_dim = 256\n",
    "dropout = 0.5\n",
    "layers = 4\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "lr_patience = 5\n",
    "lr_decay_ratio = 0.1\n",
    "clip = 5\n",
    "batch_size = 512 * 2\n",
    "epochs = 30\n",
    "log_every = 100\n",
    "early_stop = True\n",
    "patience = 10\n",
    "kfold = 5\n",
    "device = torch.device('cuda:2')\n",
    "atten_match = True \n",
    "\n",
    "w2v_window = 3\n",
    "w2v_min_count = 1\n",
    "w2v_epochs = 500\n",
    "w2v_vector_size = 128\n",
    "\n",
    "seed = 2023\n",
    "\n",
    "Fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    \"\"\"\n",
    "    重置随机数种子\n",
    "\n",
    "    Args:\n",
    "        seed(int): 种子数\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MatchModelwithATTMatchFold{}'.format(Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_input = {name: torch.tensor(products_encoded[name].values).to(device) for name in products_encoded.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "model = MatchModel(products_input).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=lr_patience, factor=lr_decay_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchModel(\n",
       "  (product_emb): ProductEmbedding(\n",
       "    (product_fea): Product(\n",
       "      (locale_emb): Embedding(6, 16)\n",
       "      (price_emb): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (len_title_emb): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (len_desc_emb): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (encode_brand_emb): Embedding(177190, 16)\n",
       "      (encode_color_emb): Embedding(203261, 16)\n",
       "      (encode_size_emb): Embedding(218061, 16)\n",
       "      (encode_model_emb): Embedding(524102, 16)\n",
       "      (encode_material_emb): Embedding(45569, 16)\n",
       "      (encode_author_emb): Embedding(30836, 16)\n",
       "      (encode_price_emb): Embedding(10, 16)\n",
       "      (encode_len_title_emb): Embedding(10, 16)\n",
       "      (encode_len_desc_emb): Embedding(10, 16)\n",
       "    )\n",
       "    (title_emb): Embedding(1410676, 384, padding_idx=1410675)\n",
       "    (title_linear): Linear(in_features=384, out_features=32, bias=True)\n",
       "    (desc_emb): Embedding(1410676, 384, padding_idx=1410675)\n",
       "    (desc_linear): Linear(in_features=384, out_features=32, bias=True)\n",
       "    (w2v_emb): Embedding(1410676, 128, padding_idx=1410675)\n",
       "    (w2v_linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "  )\n",
       "  (lstm): LSTM(304, 256, num_layers=4, batch_first=True)\n",
       "  (intra_attn): IntraAttention(\n",
       "    (w1): Linear(in_features=256, out_features=1, bias=False)\n",
       "    (w2): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (w3): Linear(in_features=256, out_features=256, bias=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (output): MatcherV2(\n",
       "    (out_linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "    (w1_linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (w2_linear): Linear(in_features=304, out_features=256, bias=False)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (loss_func): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_emb.product_fea.locale_emb.weight\ttorch.Size([6, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.price_emb.weight\ttorch.Size([16, 1])\tcuda:2\tTrue\n",
      "product_emb.product_fea.price_emb.bias\ttorch.Size([16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_title_emb.weight\ttorch.Size([16, 1])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_title_emb.bias\ttorch.Size([16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_desc_emb.weight\ttorch.Size([16, 1])\tcuda:2\tTrue\n",
      "product_emb.product_fea.len_desc_emb.bias\ttorch.Size([16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_brand_emb.weight\ttorch.Size([177190, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_color_emb.weight\ttorch.Size([203261, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_size_emb.weight\ttorch.Size([218061, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_model_emb.weight\ttorch.Size([524102, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_material_emb.weight\ttorch.Size([45569, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_author_emb.weight\ttorch.Size([30836, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_price_emb.weight\ttorch.Size([10, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_len_title_emb.weight\ttorch.Size([10, 16])\tcuda:2\tTrue\n",
      "product_emb.product_fea.encode_len_desc_emb.weight\ttorch.Size([10, 16])\tcuda:2\tTrue\n",
      "product_emb.title_emb.weight\ttorch.Size([1410676, 384])\tcuda:2\tFalse\n",
      "product_emb.title_linear.weight\ttorch.Size([32, 384])\tcuda:2\tTrue\n",
      "product_emb.title_linear.bias\ttorch.Size([32])\tcuda:2\tTrue\n",
      "product_emb.desc_emb.weight\ttorch.Size([1410676, 384])\tcuda:2\tFalse\n",
      "product_emb.desc_linear.weight\ttorch.Size([32, 384])\tcuda:2\tTrue\n",
      "product_emb.desc_linear.bias\ttorch.Size([32])\tcuda:2\tTrue\n",
      "product_emb.w2v_emb.weight\ttorch.Size([1410676, 128])\tcuda:2\tTrue\n",
      "product_emb.w2v_linear.weight\ttorch.Size([32, 128])\tcuda:2\tTrue\n",
      "product_emb.w2v_linear.bias\ttorch.Size([32])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l0\ttorch.Size([1024, 304])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l0\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l0\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l0\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l1\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l1\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l1\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l1\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l2\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l2\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l2\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l2\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.weight_ih_l3\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.weight_hh_l3\ttorch.Size([1024, 256])\tcuda:2\tTrue\n",
      "lstm.bias_ih_l3\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "lstm.bias_hh_l3\ttorch.Size([1024])\tcuda:2\tTrue\n",
      "intra_attn.w1.weight\ttorch.Size([1, 256])\tcuda:2\tTrue\n",
      "intra_attn.w2.weight\ttorch.Size([256, 256])\tcuda:2\tTrue\n",
      "intra_attn.w3.weight\ttorch.Size([256, 256])\tcuda:2\tTrue\n",
      "output.out_linear.weight\ttorch.Size([1, 256])\tcuda:2\tTrue\n",
      "output.w1_linear.weight\ttorch.Size([256, 256])\tcuda:2\tTrue\n",
      "output.w2_linear.weight\ttorch.Size([256, 304])\tcuda:2\tTrue\n",
      "1285608880\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(str(name) + '\\t' + str(param.shape) + '\\t' +\n",
    "                              str(param.device) + '\\t' + str(param.requires_grad))\n",
    "total_num = sum([param.nelement() for param in model.parameters()])\n",
    "print(total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KF = KFold(n_splits=kfold, random_state=seed, shuffle=True)\n",
    "# trn_idx_list = []\n",
    "# val_idx_list = []\n",
    "# for fold_, (trn_idx, val_idx) in enumerate(KF.split(df_train_encoded.values)):\n",
    "#     trn_idx_list.append(trn_idx)\n",
    "#     val_idx_list.append(val_idx)\n",
    "#     print(trn_idx_list[-1].shape, val_idx_list[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data/5fold_trn_idx_list.npy', trn_idx_list)\n",
    "# np.save('data/5fold_val_idx_list.npy', val_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_idx_list = np.load('data/5fold_trn_idx_list.npy', allow_pickle=True)\n",
    "val_idx_list = np.load('data/5fold_val_idx_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_split = int(len(df_train_encoded) * 0.8)\n",
    "# train_set = NNDataset(df_train_encoded[:train_split], product2id)\n",
    "# val_set = NNDataset(df_train_encoded[train_split:], product2id)\n",
    "# test_set = NNDataset(df_test_encoded, product2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Fold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-539cacdc696c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Fold' is not defined"
     ]
    }
   ],
   "source": [
    "train_set = NNDataset(df_train_encoded.iloc[trn_idx_list[Fold]], product2id)\n",
    "val_set = NNDataset(df_train_encoded.iloc[val_idx_list[Fold]], product2id)\n",
    "test_set = NNDataset(df_test_encoded, product2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2884999, 721250, 316971)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2818, 705, 310)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train model:   6%|▌         | 175/2818 [01:10<17:48,  2.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3651ce90fe77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_prev_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_locale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         loss = model.calculate_loss(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n\u001b[0m\u001b[1;32m     14\u001b[0m                                         \u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                         batch_label=batch_label_index, batch_mask=batch_mask)\n",
      "\u001b[0;32m<ipython-input-17-e9b9b37595e7>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m交叉损失熵\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_prev_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_locale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_candidate_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e9b9b37595e7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_label, batch_mask, train)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# LSTM with Mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mpack_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mpack_lstm_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mlstm_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_lstm_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/libcityng/lib/python3.9/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ac_all = []\n",
    "mrr_all = []\n",
    "min_val_loss = float('inf')\n",
    "max_val_acc = 0.0\n",
    "best_epoch = -1\n",
    "for epoch in range(epochs):\n",
    "    # train\n",
    "    print('start train epoch {}'.format(epoch))\n",
    "    model.train()\n",
    "    train_loss_list = []\n",
    "    for batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, _, batch_label_index in tqdm(train_loader, desc='train model'):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.calculate_loss(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n",
    "                                        batch_candidate_set=batch_candidate_set, batch_len=batch_len, \n",
    "                                        batch_label=batch_label_index, batch_mask=batch_mask)\n",
    "        loss.backward(retain_graph=True)\n",
    "        train_loss_list.append(loss.item())\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    train_loss = np.mean(train_loss_list)\n",
    "    # val\n",
    "    val_hit = 0\n",
    "    val_loss_list= []\n",
    "    mrr = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index in tqdm(val_loader, desc='val model'):\n",
    "            score, loss = model.predict(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n",
    "                                        batch_candidate_set=batch_candidate_set, batch_len=batch_len, \n",
    "                                        batch_label=batch_label_index, batch_mask=batch_mask)  # (batch_size, candidate_size)\n",
    "            val_loss_list.append(loss.item())\n",
    "            val_hit += score.argmax(dim=-1).eq(batch_label_index).sum().item()\n",
    "            sorted_indices = torch.argsort(score, dim=1, descending=True)\n",
    "            sorted_candidate_set = batch_candidate_set.gather(dim=1, index=sorted_indices)\n",
    "            for i in range(len(sorted_candidate_set)):\n",
    "                pred = sorted_candidate_set[i].tolist()\n",
    "                try:\n",
    "                    pred_result = pred.index(batch_label[i].item())\n",
    "                    mrr.append(1 / (pred_result + 1))\n",
    "                except:\n",
    "                    mrr.append(0)\n",
    "    val_ac = val_hit / len(val_set)\n",
    "    val_loss = np.mean(val_loss_list)\n",
    "    val_mrr = np.mean(mrr)\n",
    "    mrr_all += mrr\n",
    "    ac_all.append(val_ac)\n",
    "    lr_scheduler.step(val_ac)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print('Train Epoch {}: Train Loss {:.6f}, Val Loss {:.6f}, Val AC {:.6f}, Val MRR {:.6f}, lr {}'.format(epoch, train_loss, val_loss, val_ac, val_mrr, lr))\n",
    "    torch.save(model.state_dict(), 'ckpt/{}_{}.pt'.format(model_name, epoch))\n",
    "    if val_ac > max_val_acc:\n",
    "        wait = 0\n",
    "        min_val_loss = val_loss\n",
    "        max_val_acc = val_ac\n",
    "        best_epoch = epoch\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait == patience and early_stop:\n",
    "            print('Early stopping at epoch: %d' % epoch)\n",
    "            break\n",
    "print('Val MRR {}'.format(np.mean(mrr_all)))\n",
    "print('Val ACC {}'.format(np.mean(ac_all)))\n",
    "# load best epoch\n",
    "print('load best from {}'.format(best_epoch))\n",
    "print('min_val_loss {}, max_val_acc {}.'.format(min_val_loss, max_val_acc))\n",
    "model.load_state_dict(torch.load('ckpt/{}_{}.pt'.format(model_name, best_epoch)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本地测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('ckpt/{}_{}.pt'.format(model_name, best_epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf1b0529c980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test model: 100%|██████████| 310/310 [01:11<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# 开始评估\n",
    "test_scores = []\n",
    "test_res = []\n",
    "model.eval()\n",
    "for batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, _, batch_label_index in tqdm(test_loader, desc='test model'):\n",
    "    score, loss = model.predict(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n",
    "                                    batch_candidate_set=batch_candidate_set, batch_len=batch_len, \n",
    "                                    batch_label=batch_label_index, batch_mask=batch_mask)  # (batch_size, 100)\n",
    "    test_scores.append(score.detach().cpu().numpy())\n",
    "    sorted_indices = torch.argsort(score, dim=1, descending=True)\n",
    "    sorted_candidate_set = batch_candidate_set.gather(dim=1, index=sorted_indices)  # (B, 100)\n",
    "    test_res.append(sorted_candidate_set.detach().cpu().numpy())\n",
    "# 保存模型\n",
    "# torch.save(model.state_dict(), './ckpt/{}.pt'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set = NNDataset(df_train_encoded, product2id)\n",
    "all_loader = DataLoader(all_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all model: 100%|██████████| 3522/3522 [17:13<00:00,  3.41it/s] \n"
     ]
    }
   ],
   "source": [
    "all_loss_list = []\n",
    "all_hit = 0\n",
    "mrr_1 = []\n",
    "mrr_2 = []\n",
    "model.eval()\n",
    "for batch_prev_items, batch_locale, batch_candidate_set, batch_len, batch_mask, batch_label, batch_label_index in tqdm(all_loader, desc='all model'):\n",
    "    score, loss = model.predict(batch_prev_items=batch_prev_items, batch_locale=batch_locale, \n",
    "                                batch_candidate_set=batch_candidate_set, batch_len=batch_len, \n",
    "                                batch_label=batch_label_index, batch_mask=batch_mask)  # (batch_size, candidate_size)\n",
    "    all_loss_list.append(loss.item())\n",
    "    all_hit += score.argmax(dim=-1).eq(batch_label_index).sum().item()\n",
    "    sorted_indices = torch.argsort(score, dim=1, descending=True)\n",
    "    sorted_candidate_set = batch_candidate_set.gather(dim=1, index=sorted_indices)\n",
    "    for i in range(len(sorted_candidate_set)):\n",
    "        pred = sorted_candidate_set[i].tolist()\n",
    "        try:\n",
    "            pred_result = pred.index(batch_label[i].item())\n",
    "            mrr_1.append(1 / (pred_result + 1))\n",
    "        except:\n",
    "            mrr_1.append(0)\n",
    "    for i in range(len(batch_candidate_set)):\n",
    "        pred = batch_candidate_set[i].tolist()\n",
    "        try:\n",
    "            pred_result = pred.index(batch_label[i].item())\n",
    "            mrr_2.append(1 / (pred_result + 1))\n",
    "        except:\n",
    "            mrr_2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316971, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res = np.concatenate(test_res, axis=0)\n",
    "test_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/sessions_test_task1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_unencoded = []\n",
    "for x in test_res:\n",
    "    test_res_unencoded.append([id2product[id_] for id_ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    316971.0\n",
       "mean        100.0\n",
       "std           0.0\n",
       "min         100.0\n",
       "25%         100.0\n",
       "50%         100.0\n",
       "75%         100.0\n",
       "max         100.0\n",
       "Name: next_item_prediction, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['next_item_prediction'] = test_res_unencoded\n",
    "df_test['next_item_prediction'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['locale', 'next_item_prediction']].to_parquet('output/submission_task1_{}_{}_{}_{}.parquet'.format(seed, model_name, best_epoch, model.input_size), engine='pyarrow')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1111"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
